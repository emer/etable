// Code generated by numeric.gen.go.tmpl. DO NOT EDIT.

// Copyright (c) 2019, The Emergent Authors. All rights reserved.
// Use of this source code is governed by a BSD-style
// license that can be found in the LICENSE file.

package etensor

import (
	"errors"
	"fmt"
	"log"
	"math"
	"strconv"
	"strings"

	"cogentcore.org/core/laser"
	"github.com/apache/arrow/go/arrow/array"
	"github.com/apache/arrow/go/arrow/memory"
	"github.com/apache/arrow/go/arrow/tensor"
	"github.com/emer/etable/v2/bitslice"
	"gonum.org/v1/gonum/mat"
)

// Int64 is an n-dim array of int64s.
type Int64 struct {
	Shape
	Values []int64
	Nulls  bitslice.Slice
	Meta   map[string]string
}

// NewInt64 returns a new n-dimensional array of int64s.
// If strides is nil, row-major strides will be inferred.
// If names is nil, a slice of empty strings will be created.
// Nulls are initialized to nil.
func NewInt64(shape, strides []int, names []string) *Int64 {
	tsr := &Int64{}
	tsr.SetShape(shape, strides, names)
	tsr.Values = make([]int64, tsr.Len())
	return tsr
}

// NewInt64Shape returns a new n-dimensional array of int64s.
// Using shape structure instead of separate slices, and optionally
// existing values if vals != nil (must be of proper length) -- we
// directly set our internal Values = vals, thereby sharing the same
// underlying data. Nulls are initialized to nil.
func NewInt64Shape(shape *Shape, vals []int64) *Int64 {
	tsr := &Int64{}
	tsr.CopyShape(shape)
	if vals != nil {
		if len(vals) != tsr.Len() {
			log.Printf("etensor.NewInt64Shape: length of provided vals: %d not proper length: %d", len(vals), tsr.Len())
			tsr.Values = make([]int64, tsr.Len())
		} else {
			tsr.Values = vals
		}
	} else {
		tsr.Values = make([]int64, tsr.Len())
	}
	return tsr
}

func (tsr *Int64) ShapeObj() *Shape       { return &tsr.Shape }
func (tsr *Int64) DataType() Type         { return INT64 }
func (tsr *Int64) Value(i []int) int64    { j := tsr.Offset(i); return tsr.Values[j] }
func (tsr *Int64) Value1D(i int) int64    { return tsr.Values[i] }
func (tsr *Int64) Set(i []int, val int64) { j := tsr.Offset(i); tsr.Values[j] = val }
func (tsr *Int64) Set1D(i int, val int64) { tsr.Values[i] = val }
func (tsr *Int64) AddScalar(i []int, val int64) int64 {
	j := tsr.Offset(i)
	tsr.Values[j] += val
	return tsr.Values[j]
}
func (tsr *Int64) MulScalar(i []int, val int64) int64 {
	j := tsr.Offset(i)
	tsr.Values[j] *= val
	return tsr.Values[j]
}

// IsNull returns true if the given index has been flagged as a Null
// (undefined, not present) value
func (tsr *Int64) IsNull(i []int) bool {
	if tsr.Nulls == nil {
		return false
	}
	j := tsr.Offset(i)
	return tsr.Nulls.Index(j)
}

// IsNull1D returns true if the given 1-dimensional index has been flagged as a Null
// (undefined, not present) value
func (tsr *Int64) IsNull1D(i int) bool {
	if tsr.Nulls == nil {
		return false
	}
	return tsr.Nulls.Index(i)
}

// SetNull sets whether given index has a null value or not.
// All values are assumed valid (non-Null) until marked otherwise, and calling
// this method creates a Null bitslice map if one has not already been set yet.
func (tsr *Int64) SetNull(i []int, nul bool) {
	if tsr.Nulls == nil {
		tsr.Nulls = bitslice.Make(tsr.Len(), 0)
	}
	j := tsr.Offset(i)
	tsr.Nulls.Set(j, nul)
}

// SetNull1D sets whether given 1-dimensional index has a null value or not.
// All values are assumed valid (non-Null) until marked otherwise, and calling
// this method creates a Null bitslice map if one has not already been set yet.
func (tsr *Int64) SetNull1D(i int, nul bool) {
	if tsr.Nulls == nil {
		tsr.Nulls = bitslice.Make(tsr.Len(), 0)
	}
	tsr.Nulls.Set(i, nul)
}

func (tsr *Int64) FloatValue(i []int) float64      { j := tsr.Offset(i); return float64(tsr.Values[j]) }
func (tsr *Int64) SetFloat(i []int, val float64) { j := tsr.Offset(i); tsr.Values[j] = int64(val) }

func (tsr *Int64) StringValue(i []int) string { j := tsr.Offset(i); return laser.ToString(tsr.Values[j]) }
func (tsr *Int64) SetString(i []int, val string) {
	if fv, err := strconv.ParseFloat(val, 64); err == nil {
		j := tsr.Offset(i)
		tsr.Values[j] = int64(fv)
	}
}

func (tsr *Int64) FloatValue1D(off int) float64      { return float64(tsr.Values[off]) }
func (tsr *Int64) SetFloat1D(off int, val float64) { tsr.Values[off] = int64(val) }

func (tsr *Int64) FloatValueRowCell(row, cell int) float64 {
	_, sz := tsr.RowCellSize()
	return float64(tsr.Values[row*sz+cell])
}
func (tsr *Int64) SetFloatRowCell(row, cell int, val float64) {
	_, sz := tsr.RowCellSize()
	tsr.Values[row*sz+cell] = int64(val)
}

// Floats sets []float64 slice of all elements in the tensor
// (length is ensured to be sufficient).
// This can be used for all of the gonum/floats methods
// for basic math, gonum/stats, etc.
func (tsr *Int64) Floats(flt *[]float64) {
	SetFloat64SliceLen(flt, len(tsr.Values))
	for j, vl := range tsr.Values {
		(*flt)[j] = float64(vl)
	}
}

// SetFloats sets tensor values from a []float64 slice (copies values).
func (tsr *Int64) SetFloats(vals []float64) {
	sz := min(len(tsr.Values), len(vals))
	for j := 0; j < sz; j++ {
		tsr.Values[j] = int64(vals[j])
	}
}

func (tsr *Int64) StringValue1D(off int) string { return laser.ToString(tsr.Values[off]) }
func (tsr *Int64) SetString1D(off int, val string) {
	if fv, err := strconv.ParseFloat(val, 64); err == nil {
		tsr.Values[off] = int64(fv)
	}
}

func (tsr *Int64) StringValueRowCell(row, cell int) string {
	_, sz := tsr.RowCellSize()
	return laser.ToString(tsr.Values[row*sz+cell])
}
func (tsr *Int64) SetStringRowCell(row, cell int, val string) {
	if fv, err := strconv.ParseFloat(val, 64); err == nil {
		_, sz := tsr.RowCellSize()
		tsr.Values[row*sz+cell] = int64(fv)
	}
}

// Range returns the min, max (and associated indexes, -1 = no values) for the tensor.
// This is needed for display and is thus in the core api in optimized form
// Other math operations can be done using gonum/floats package.
func (tsr *Int64) Range() (min, max float64, minIndex, maxIndex int) {
	minIndex = -1
	maxIndex = -1
	for j, vl := range tsr.Values {
		fv := float64(vl)
		if math.IsNaN(fv) {
			continue
		}
		if fv < min || minIndex < 0 {
			min = fv
			minIndex = j
		}
		if fv > max || maxIndex < 0 {
			max = fv
			maxIndex = j
		}
	}
	return
}

// Agg applies given aggregation function to each element in the tensor
// (automatically skips IsNull and NaN elements), using float64 conversions of the values.
// init is the initial value for the agg variable. returns final aggregate value
func (tsr *Int64) Agg(ini float64, fun AggFunc) float64 {
	ag := ini
	for j, vl := range tsr.Values {
		val := float64(vl)
		if !tsr.IsNull1D(j) && !math.IsNaN(val) {
			ag = fun(j, val, ag)
		}
	}
	return ag
}

// Eval applies given function to each element in the tensor (automatically
// skips IsNull and NaN elements), using float64 conversions of the values.
// Puts the results into given float64 slice, which is ensured to be of the proper length.
func (tsr *Int64) Eval(res *[]float64, fun EvalFunc) {
	ln := tsr.Len()
	if len(*res) != ln {
		*res = make([]float64, ln)
	}
	for j, vl := range tsr.Values {
		val := float64(vl)
		if !tsr.IsNull1D(j) && !math.IsNaN(val) {
			(*res)[j] = fun(j, val)
		}
	}
}

// SetFunc applies given function to each element in the tensor (automatically
// skips IsNull and NaN elements), using float64 conversions of the values.
// Writes the results back into the same tensor elements.
func (tsr *Int64) SetFunc(fun EvalFunc) {
	for j, vl := range tsr.Values {
		val := float64(vl)
		if !tsr.IsNull1D(j) && !math.IsNaN(val) {
			tsr.Values[j] = int64(fun(j, val))
		}
	}
}

// SetZeros is simple convenience function initialize all values to 0
func (tsr *Int64) SetZeros() {
	for j := range tsr.Values {
		tsr.Values[j] = 0
	}
}

// Clone clones this tensor, creating a duplicate copy of itself with its
// own separate memory representation of all the values, and returns
// that as a Tensor (which can be converted into the known type as needed).
func (tsr *Int64) Clone() Tensor {
	csr := NewInt64Shape(&tsr.Shape, nil)
	copy(csr.Values, tsr.Values)
	if tsr.Nulls != nil {
		csr.Nulls = tsr.Nulls.Clone()
	}
	return csr
}

// CopyFrom copies all avail values from other tensor into this tensor, with an
// optimized implementation if the other tensor is of the same type, and
// otherwise it goes through appropriate standard type.
// Copies Null state as well if present.
func (tsr *Int64) CopyFrom(frm Tensor) {
	if fsm, ok := frm.(*Int64); ok {
		copy(tsr.Values, fsm.Values)
		if fsm.Nulls != nil {
			if tsr.Nulls == nil {
				tsr.Nulls = bitslice.Make(tsr.Len(), 0)
			}
			copy(tsr.Nulls, fsm.Nulls)
		}
		return
	}
	sz := min(len(tsr.Values), frm.Len())
	for i := 0; i < sz; i++ {
		tsr.Values[i] = int64(frm.FloatValue1D(i))
		if frm.IsNull1D(i) {
			tsr.SetNull1D(i, true)
		}
	}
}

// CopyShapeFrom copies just the shape from given source tensor
// calling SetShape with the shape params from source (see for more docs).
func (tsr *Int64) CopyShapeFrom(frm Tensor) {
	tsr.SetShape(frm.Shapes(), frm.Strides(), frm.DimNames())
}

// CopyCellsFrom copies given range of values from other tensor into this tensor,
// using flat 1D indexes: to = starting index in this Tensor to start copying into,
// start = starting index on from Tensor to start copying from, and n = number of
// values to copy.  Uses an optimized implementation if the other tensor is
// of the same type, and otherwise it goes through appropriate standard type.
func (tsr *Int64) CopyCellsFrom(frm Tensor, to, start, n int) {
	if fsm, ok := frm.(*Int64); ok {
		for i := 0; i < n; i++ {
			tsr.Values[to+i] = fsm.Values[start+i]
			if fsm.IsNull1D(start + i) {
				tsr.SetNull1D(to+i, true)
			}
		}
		return
	}
	for i := 0; i < n; i++ {
		tsr.Values[to+i] = int64(frm.FloatValue1D(start + i))
		if frm.IsNull1D(start + i) {
			tsr.SetNull1D(to+i, true)
		}
	}
}

// SetShape sets the shape params, resizing backing storage appropriately
func (tsr *Int64) SetShape(shape, strides []int, names []string) {
	tsr.Shape.SetShape(shape, strides, names)
	nln := tsr.Len()
	if cap(tsr.Values) >= nln {
		tsr.Values = tsr.Values[0:nln]
	} else {
		nv := make([]int64, nln)
		copy(nv, tsr.Values)
		tsr.Values = nv
	}
	if tsr.Nulls != nil {
		tsr.Nulls.SetLen(nln)
	}
}

// SetNumRows sets the number of rows (outer-most dimension) in a RowMajor organized tensor.
func (tsr *Int64) SetNumRows(rows int) {
	if !tsr.IsRowMajor() {
		return
	}
	rows = max(1, rows) // must be > 0
	_, cells := tsr.RowCellSize()
	nln := rows * cells
	tsr.Shape.Shp[0] = rows
	if cap(tsr.Values) >= nln {
		tsr.Values = tsr.Values[0:nln]
	} else {
		nv := make([]int64, nln)
		copy(nv, tsr.Values)
		tsr.Values = nv
	}
	if tsr.Nulls != nil {
		tsr.Nulls.SetLen(nln)
	}
}

// SubSpace returns a new tensor with innermost subspace at given
// offset(s) in outermost dimension(s) (len(offs) < NumDims).
// Only valid for row or column major layouts.
// The new tensor points to the values of the this tensor (i.e., modifications
// will affect both), as its Values slice is a view onto the original (which
// is why only inner-most contiguous supsaces are supported).
// Use Clone() method to separate the two.
// Null value bits are NOT shared but are copied if present.
func (tsr *Int64) SubSpace(offs []int) Tensor {
	ss, _ := tsr.SubSpaceTry(offs)
	return ss
}

// SubSpaceTry returns a new tensor with innermost subspace at given
// offset(s) in outermost dimension(s) (len(offs) < NumDims).
// Try version returns an error message if the offs do not fit in tensor Shape.
// Only valid for row or column major layouts.
// The new tensor points to the values of the this tensor (i.e., modifications
// will affect both), as its Values slice is a view onto the original (which
// is why only inner-most contiguous supsaces are supported).
// Use Clone() method to separate the two.
// Null value bits are NOT shared but are copied if present.
func (tsr *Int64) SubSpaceTry(offs []int) (Tensor, error) {
	nd := tsr.NumDims()
	od := len(offs)
	if od >= nd {
		return nil, errors.New("SubSpace len(offsets) for outer dimensions was >= NumDims -- must be less")
	}
	id := nd - od
	if tsr.IsRowMajor() {
		stsr := &Int64{}
		stsr.SetShape(tsr.Shp[od:], nil, tsr.Nms[od:]) // row major def
		sti := make([]int, nd)
		copy(sti, offs)
		stoff := tsr.Offset(sti)
		sln := stsr.Len()
		stsr.Values = tsr.Values[stoff : stoff+sln]
		if tsr.Nulls != nil {
			stsr.Nulls = tsr.Nulls.SubSlice(stoff, stoff+sln)
		}
		return stsr, nil
	} else if tsr.IsColMajor() {
		stsr := &Int64{}
		stsr.SetShape(tsr.Shp[:id], nil, tsr.Nms[:id])
		stsr.Strd = ColMajorStrides(stsr.Shp)
		sti := make([]int, nd)
		for i := id; i < nd; i++ {
			sti[i] = offs[i-id]
		}
		stoff := tsr.Offset(sti)
		sln := stsr.Len()
		stsr.Values = tsr.Values[stoff : stoff+sln]
		if tsr.Nulls != nil {
			stsr.Nulls = tsr.Nulls.SubSlice(stoff, stoff+sln)
		}
		return stsr, nil
	}
	return nil, errors.New("SubSpace only valid for RowMajor or ColMajor tensors")
}

// Label satisfies the gi.Labeler interface for a summary description of the tensor
func (tsr *Int64) Label() string {
	return fmt.Sprintf("Int64: %s", tsr.Shape.String())
}

// String satisfies the fmt.Stringer interface for string of tensor data
func (tsr *Int64) String() string {
	str := tsr.Label()
	sz := len(tsr.Values)
	if sz > 1000 {
		return str
	}
	var b strings.Builder
	b.WriteString(str)
	b.WriteString("\n")
	oddRow := true
	rows, cols, _, _ := Prjn2DShape(&tsr.Shape, oddRow)
	for r := 0; r < rows; r++ {
		rc, _ := Prjn2DCoords(&tsr.Shape, oddRow, r, 0)
		b.WriteString(fmt.Sprintf("%v: ", rc))
		for c := 0; c < cols; c++ {
			vl := Prjn2DValue(tsr, oddRow, r, c)
			b.WriteString(fmt.Sprintf("%7g ", vl))
		}
		b.WriteString("\n")
	}
	return b.String()
}

// ToArrow returns the apache arrow equivalent of the tensor
func (tsr *Int64) ToArrow() *tensor.Int64 {
	bld := array.NewInt64Builder(memory.DefaultAllocator)
	if tsr.Nulls != nil {
		bld.AppendValues(tsr.Values, tsr.Nulls.ToBools())
	} else {
		bld.AppendValues(tsr.Values, nil)
	}
	vec := bld.NewInt64Array()
	return tensor.NewInt64(vec.Data(), tsr.Shape64(), tsr.Strides64(), tsr.DimNames())
}

// FromArrow intializes this tensor from an arrow tensor of same type
// cpy = true means make a copy of the arrow data, otherwise it directly
// refers to its values slice -- we do not Retain() on that data so it is up
// to the go GC and / or your own memory management policies to ensure the data
// remains intact!
func (tsr *Int64) FromArrow(arw *tensor.Int64, cpy bool) {
	nms := make([]string, arw.NumDims()) // note: would be nice if it exposed DimNames()
	for i := range nms {
		nms[i] = arw.DimName(i)
	}
	tsr.SetShape64(arw.Shape(), arw.Strides(), nms)
	if cpy {
		vls := arw.Int64Values()
		tsr.Values = make([]int64, tsr.Len())
		copy(tsr.Values, vls)
	} else {
		tsr.Values = arw.Int64Values()
	}
	// note: doesn't look like the Data() exposes the nulls themselves so it is not
	// clear we can copy the null values -- nor does it seem that the tensor class
	// exposes it either!  https://github.com/apache/arrow/issues/3496
	// nln := arw.Data().NullN()
	// if nln > 0 {
	// }
}

// Dims is the gonum/mat.Matrix interface method for returning the dimensionality of the
// 2D Matrix.  Assumes Row-major ordering and logs an error if NumDims < 2.
func (tsr *Int64) Dims() (r, c int) {
	nd := tsr.NumDims()
	if nd < 2 {
		log.Println("etensor Dims gonum Matrix call made on Tensor with dims < 2")
		return 0, 0
	}
	return tsr.Dim(nd - 2), tsr.Dim(nd - 1)
}

// At is the gonum/mat.Matrix interface method for returning 2D matrix element at given
// row, column index.  Assumes Row-major ordering and logs an error if NumDims < 2.
func (tsr *Int64) At(i, j int) float64 {
	nd := tsr.NumDims()
	if nd < 2 {
		log.Println("etensor Dims gonum Matrix call made on Tensor with dims < 2")
		return 0
	} else if nd == 2 {
		return tsr.FloatValue([]int{i, j})
	} else {
		ix := make([]int, nd)
		ix[nd-2] = i
		ix[nd-1] = j
		return tsr.FloatValue(ix)
	}
}

// T is the gonum/mat.Matrix transpose method.
// It performs an implicit transpose by returning the receiver inside a Transpose.
func (tsr *Int64) T() mat.Matrix {
	return mat.Transpose{tsr}
}

// Symmetric is the gonum/mat.Matrix interface method for returning the dimensionality of a symmetric
// 2D Matrix.  Logs error if called on non-symmetric matrix.
func (tsr *Int64) Symmetric() (r int) {
	nd := tsr.NumDims()
	if nd < 2 {
		log.Println("etensor Symmetric gonum Matrix call made on Tensor with dims < 2")
		return 0
	}
	if tsr.Dim(nd-2) != tsr.Dim(nd-1) {
		log.Println("etensor Symmatrics gonum Matrix call made on Tensor that is not symmetric")
		return 0
	}
	return tsr.Dim(nd - 1)
}

// SymmetricDim is the gonum/mat.Matrix interface method for returning the dimensionality of a symmetric
// 2D Matrix.  Logs error if called on non-symmetric matrix.
func (tsr *Int64) SymmetricDim() int {
	nd := tsr.NumDims()
	if nd < 2 {
		log.Println("etensor Symmetric gonum Matrix call made on Tensor with dims < 2")
		return 0
	}
	if tsr.Dim(nd-2) != tsr.Dim(nd-1) {
		log.Println("etensor Symmetric gonum Matrix call made on Tensor that is not symmetric")
		return 0
	}
	return tsr.Dim(nd - 1)
}

// SetMetaData sets a key=value meta data (stored as a map[string]string).
// For TensorGrid display: top-zero=+/-, odd-row=+/-, image=+/-,
// min, max set fixed min / max values, background=color
func (tsr *Int64) SetMetaData(key, val string) {
	if tsr.Meta == nil {
		tsr.Meta = make(map[string]string)
	}
	tsr.Meta[key] = val
}

// MetaData retrieves value of given key, bool = false if not set
func (tsr *Int64) MetaData(key string) (string, bool) {
	if tsr.Meta == nil {
		return "", false
	}
	val, ok := tsr.Meta[key]
	return val, ok
}

// MetaDataMap returns the underlying map used for meta data
func (tsr *Int64) MetaDataMap() map[string]string {
	return tsr.Meta
}

// CopyMetaData copies meta data from given source tensor
func (tsr *Int64) CopyMetaData(frm Tensor) {
	fmap := frm.MetaDataMap()
	if len(fmap) == 0 {
		return
	}
	if tsr.Meta == nil {
		tsr.Meta = make(map[string]string)
	}
	for k, v := range fmap {
		tsr.Meta[k] = v
	}
}

// Uint64 is an n-dim array of uint64s.
type Uint64 struct {
	Shape
	Values []uint64
	Nulls  bitslice.Slice
	Meta   map[string]string
}

// NewUint64 returns a new n-dimensional array of uint64s.
// If strides is nil, row-major strides will be inferred.
// If names is nil, a slice of empty strings will be created.
// Nulls are initialized to nil.
func NewUint64(shape, strides []int, names []string) *Uint64 {
	tsr := &Uint64{}
	tsr.SetShape(shape, strides, names)
	tsr.Values = make([]uint64, tsr.Len())
	return tsr
}

// NewUint64Shape returns a new n-dimensional array of uint64s.
// Using shape structure instead of separate slices, and optionally
// existing values if vals != nil (must be of proper length) -- we
// directly set our internal Values = vals, thereby sharing the same
// underlying data. Nulls are initialized to nil.
func NewUint64Shape(shape *Shape, vals []uint64) *Uint64 {
	tsr := &Uint64{}
	tsr.CopyShape(shape)
	if vals != nil {
		if len(vals) != tsr.Len() {
			log.Printf("etensor.NewUint64Shape: length of provided vals: %d not proper length: %d", len(vals), tsr.Len())
			tsr.Values = make([]uint64, tsr.Len())
		} else {
			tsr.Values = vals
		}
	} else {
		tsr.Values = make([]uint64, tsr.Len())
	}
	return tsr
}

func (tsr *Uint64) ShapeObj() *Shape        { return &tsr.Shape }
func (tsr *Uint64) DataType() Type          { return UINT64 }
func (tsr *Uint64) Value(i []int) uint64    { j := tsr.Offset(i); return tsr.Values[j] }
func (tsr *Uint64) Value1D(i int) uint64    { return tsr.Values[i] }
func (tsr *Uint64) Set(i []int, val uint64) { j := tsr.Offset(i); tsr.Values[j] = val }
func (tsr *Uint64) Set1D(i int, val uint64) { tsr.Values[i] = val }
func (tsr *Uint64) AddScalar(i []int, val uint64) uint64 {
	j := tsr.Offset(i)
	tsr.Values[j] += val
	return tsr.Values[j]
}
func (tsr *Uint64) MulScalar(i []int, val uint64) uint64 {
	j := tsr.Offset(i)
	tsr.Values[j] *= val
	return tsr.Values[j]
}

// IsNull returns true if the given index has been flagged as a Null
// (undefined, not present) value
func (tsr *Uint64) IsNull(i []int) bool {
	if tsr.Nulls == nil {
		return false
	}
	j := tsr.Offset(i)
	return tsr.Nulls.Index(j)
}

// IsNull1D returns true if the given 1-dimensional index has been flagged as a Null
// (undefined, not present) value
func (tsr *Uint64) IsNull1D(i int) bool {
	if tsr.Nulls == nil {
		return false
	}
	return tsr.Nulls.Index(i)
}

// SetNull sets whether given index has a null value or not.
// All values are assumed valid (non-Null) until marked otherwise, and calling
// this method creates a Null bitslice map if one has not already been set yet.
func (tsr *Uint64) SetNull(i []int, nul bool) {
	if tsr.Nulls == nil {
		tsr.Nulls = bitslice.Make(tsr.Len(), 0)
	}
	j := tsr.Offset(i)
	tsr.Nulls.Set(j, nul)
}

// SetNull1D sets whether given 1-dimensional index has a null value or not.
// All values are assumed valid (non-Null) until marked otherwise, and calling
// this method creates a Null bitslice map if one has not already been set yet.
func (tsr *Uint64) SetNull1D(i int, nul bool) {
	if tsr.Nulls == nil {
		tsr.Nulls = bitslice.Make(tsr.Len(), 0)
	}
	tsr.Nulls.Set(i, nul)
}

func (tsr *Uint64) FloatValue(i []int) float64      { j := tsr.Offset(i); return float64(tsr.Values[j]) }
func (tsr *Uint64) SetFloat(i []int, val float64) { j := tsr.Offset(i); tsr.Values[j] = uint64(val) }

func (tsr *Uint64) StringValue(i []int) string {
	j := tsr.Offset(i)
	return laser.ToString(tsr.Values[j])
}
func (tsr *Uint64) SetString(i []int, val string) {
	if fv, err := strconv.ParseFloat(val, 64); err == nil {
		j := tsr.Offset(i)
		tsr.Values[j] = uint64(fv)
	}
}

func (tsr *Uint64) FloatValue1D(off int) float64      { return float64(tsr.Values[off]) }
func (tsr *Uint64) SetFloat1D(off int, val float64) { tsr.Values[off] = uint64(val) }

func (tsr *Uint64) FloatValueRowCell(row, cell int) float64 {
	_, sz := tsr.RowCellSize()
	return float64(tsr.Values[row*sz+cell])
}
func (tsr *Uint64) SetFloatRowCell(row, cell int, val float64) {
	_, sz := tsr.RowCellSize()
	tsr.Values[row*sz+cell] = uint64(val)
}

// Floats sets []float64 slice of all elements in the tensor
// (length is ensured to be sufficient).
// This can be used for all of the gonum/floats methods
// for basic math, gonum/stats, etc.
func (tsr *Uint64) Floats(flt *[]float64) {
	SetFloat64SliceLen(flt, len(tsr.Values))
	for j, vl := range tsr.Values {
		(*flt)[j] = float64(vl)
	}
}

// SetFloats sets tensor values from a []float64 slice (copies values).
func (tsr *Uint64) SetFloats(vals []float64) {
	sz := min(len(tsr.Values), len(vals))
	for j := 0; j < sz; j++ {
		tsr.Values[j] = uint64(vals[j])
	}
}

func (tsr *Uint64) StringValue1D(off int) string { return laser.ToString(tsr.Values[off]) }
func (tsr *Uint64) SetString1D(off int, val string) {
	if fv, err := strconv.ParseFloat(val, 64); err == nil {
		tsr.Values[off] = uint64(fv)
	}
}

func (tsr *Uint64) StringValueRowCell(row, cell int) string {
	_, sz := tsr.RowCellSize()
	return laser.ToString(tsr.Values[row*sz+cell])
}
func (tsr *Uint64) SetStringRowCell(row, cell int, val string) {
	if fv, err := strconv.ParseFloat(val, 64); err == nil {
		_, sz := tsr.RowCellSize()
		tsr.Values[row*sz+cell] = uint64(fv)
	}
}

// Range returns the min, max (and associated indexes, -1 = no values) for the tensor.
// This is needed for display and is thus in the core api in optimized form
// Other math operations can be done using gonum/floats package.
func (tsr *Uint64) Range() (min, max float64, minIndex, maxIndex int) {
	minIndex = -1
	maxIndex = -1
	for j, vl := range tsr.Values {
		fv := float64(vl)
		if math.IsNaN(fv) {
			continue
		}
		if fv < min || minIndex < 0 {
			min = fv
			minIndex = j
		}
		if fv > max || maxIndex < 0 {
			max = fv
			maxIndex = j
		}
	}
	return
}

// Agg applies given aggregation function to each element in the tensor
// (automatically skips IsNull and NaN elements), using float64 conversions of the values.
// init is the initial value for the agg variable. returns final aggregate value
func (tsr *Uint64) Agg(ini float64, fun AggFunc) float64 {
	ag := ini
	for j, vl := range tsr.Values {
		val := float64(vl)
		if !tsr.IsNull1D(j) && !math.IsNaN(val) {
			ag = fun(j, val, ag)
		}
	}
	return ag
}

// Eval applies given function to each element in the tensor (automatically
// skips IsNull and NaN elements), using float64 conversions of the values.
// Puts the results into given float64 slice, which is ensured to be of the proper length.
func (tsr *Uint64) Eval(res *[]float64, fun EvalFunc) {
	ln := tsr.Len()
	if len(*res) != ln {
		*res = make([]float64, ln)
	}
	for j, vl := range tsr.Values {
		val := float64(vl)
		if !tsr.IsNull1D(j) && !math.IsNaN(val) {
			(*res)[j] = fun(j, val)
		}
	}
}

// SetFunc applies given function to each element in the tensor (automatically
// skips IsNull and NaN elements), using float64 conversions of the values.
// Writes the results back into the same tensor elements.
func (tsr *Uint64) SetFunc(fun EvalFunc) {
	for j, vl := range tsr.Values {
		val := float64(vl)
		if !tsr.IsNull1D(j) && !math.IsNaN(val) {
			tsr.Values[j] = uint64(fun(j, val))
		}
	}
}

// SetZeros is simple convenience function initialize all values to 0
func (tsr *Uint64) SetZeros() {
	for j := range tsr.Values {
		tsr.Values[j] = 0
	}
}

// Clone clones this tensor, creating a duplicate copy of itself with its
// own separate memory representation of all the values, and returns
// that as a Tensor (which can be converted into the known type as needed).
func (tsr *Uint64) Clone() Tensor {
	csr := NewUint64Shape(&tsr.Shape, nil)
	copy(csr.Values, tsr.Values)
	if tsr.Nulls != nil {
		csr.Nulls = tsr.Nulls.Clone()
	}
	return csr
}

// CopyFrom copies all avail values from other tensor into this tensor, with an
// optimized implementation if the other tensor is of the same type, and
// otherwise it goes through appropriate standard type.
// Copies Null state as well if present.
func (tsr *Uint64) CopyFrom(frm Tensor) {
	if fsm, ok := frm.(*Uint64); ok {
		copy(tsr.Values, fsm.Values)
		if fsm.Nulls != nil {
			if tsr.Nulls == nil {
				tsr.Nulls = bitslice.Make(tsr.Len(), 0)
			}
			copy(tsr.Nulls, fsm.Nulls)
		}
		return
	}
	sz := min(len(tsr.Values), frm.Len())
	for i := 0; i < sz; i++ {
		tsr.Values[i] = uint64(frm.FloatValue1D(i))
		if frm.IsNull1D(i) {
			tsr.SetNull1D(i, true)
		}
	}
}

// CopyShapeFrom copies just the shape from given source tensor
// calling SetShape with the shape params from source (see for more docs).
func (tsr *Uint64) CopyShapeFrom(frm Tensor) {
	tsr.SetShape(frm.Shapes(), frm.Strides(), frm.DimNames())
}

// CopyCellsFrom copies given range of values from other tensor into this tensor,
// using flat 1D indexes: to = starting index in this Tensor to start copying into,
// start = starting index on from Tensor to start copying from, and n = number of
// values to copy.  Uses an optimized implementation if the other tensor is
// of the same type, and otherwise it goes through appropriate standard type.
func (tsr *Uint64) CopyCellsFrom(frm Tensor, to, start, n int) {
	if fsm, ok := frm.(*Uint64); ok {
		for i := 0; i < n; i++ {
			tsr.Values[to+i] = fsm.Values[start+i]
			if fsm.IsNull1D(start + i) {
				tsr.SetNull1D(to+i, true)
			}
		}
		return
	}
	for i := 0; i < n; i++ {
		tsr.Values[to+i] = uint64(frm.FloatValue1D(start + i))
		if frm.IsNull1D(start + i) {
			tsr.SetNull1D(to+i, true)
		}
	}
}

// SetShape sets the shape params, resizing backing storage appropriately
func (tsr *Uint64) SetShape(shape, strides []int, names []string) {
	tsr.Shape.SetShape(shape, strides, names)
	nln := tsr.Len()
	if cap(tsr.Values) >= nln {
		tsr.Values = tsr.Values[0:nln]
	} else {
		nv := make([]uint64, nln)
		copy(nv, tsr.Values)
		tsr.Values = nv
	}
	if tsr.Nulls != nil {
		tsr.Nulls.SetLen(nln)
	}
}

// SetNumRows sets the number of rows (outer-most dimension) in a RowMajor organized tensor.
func (tsr *Uint64) SetNumRows(rows int) {
	if !tsr.IsRowMajor() {
		return
	}
	rows = max(1, rows) // must be > 0
	_, cells := tsr.RowCellSize()
	nln := rows * cells
	tsr.Shape.Shp[0] = rows
	if cap(tsr.Values) >= nln {
		tsr.Values = tsr.Values[0:nln]
	} else {
		nv := make([]uint64, nln)
		copy(nv, tsr.Values)
		tsr.Values = nv
	}
	if tsr.Nulls != nil {
		tsr.Nulls.SetLen(nln)
	}
}

// SubSpace returns a new tensor with innermost subspace at given
// offset(s) in outermost dimension(s) (len(offs) < NumDims).
// Only valid for row or column major layouts.
// The new tensor points to the values of the this tensor (i.e., modifications
// will affect both), as its Values slice is a view onto the original (which
// is why only inner-most contiguous supsaces are supported).
// Use Clone() method to separate the two.
// Null value bits are NOT shared but are copied if present.
func (tsr *Uint64) SubSpace(offs []int) Tensor {
	ss, _ := tsr.SubSpaceTry(offs)
	return ss
}

// SubSpaceTry returns a new tensor with innermost subspace at given
// offset(s) in outermost dimension(s) (len(offs) < NumDims).
// Try version returns an error message if the offs do not fit in tensor Shape.
// Only valid for row or column major layouts.
// The new tensor points to the values of the this tensor (i.e., modifications
// will affect both), as its Values slice is a view onto the original (which
// is why only inner-most contiguous supsaces are supported).
// Use Clone() method to separate the two.
// Null value bits are NOT shared but are copied if present.
func (tsr *Uint64) SubSpaceTry(offs []int) (Tensor, error) {
	nd := tsr.NumDims()
	od := len(offs)
	if od >= nd {
		return nil, errors.New("SubSpace len(offsets) for outer dimensions was >= NumDims -- must be less")
	}
	id := nd - od
	if tsr.IsRowMajor() {
		stsr := &Uint64{}
		stsr.SetShape(tsr.Shp[od:], nil, tsr.Nms[od:]) // row major def
		sti := make([]int, nd)
		copy(sti, offs)
		stoff := tsr.Offset(sti)
		sln := stsr.Len()
		stsr.Values = tsr.Values[stoff : stoff+sln]
		if tsr.Nulls != nil {
			stsr.Nulls = tsr.Nulls.SubSlice(stoff, stoff+sln)
		}
		return stsr, nil
	} else if tsr.IsColMajor() {
		stsr := &Uint64{}
		stsr.SetShape(tsr.Shp[:id], nil, tsr.Nms[:id])
		stsr.Strd = ColMajorStrides(stsr.Shp)
		sti := make([]int, nd)
		for i := id; i < nd; i++ {
			sti[i] = offs[i-id]
		}
		stoff := tsr.Offset(sti)
		sln := stsr.Len()
		stsr.Values = tsr.Values[stoff : stoff+sln]
		if tsr.Nulls != nil {
			stsr.Nulls = tsr.Nulls.SubSlice(stoff, stoff+sln)
		}
		return stsr, nil
	}
	return nil, errors.New("SubSpace only valid for RowMajor or ColMajor tensors")
}

// Label satisfies the gi.Labeler interface for a summary description of the tensor
func (tsr *Uint64) Label() string {
	return fmt.Sprintf("Uint64: %s", tsr.Shape.String())
}

// String satisfies the fmt.Stringer interface for string of tensor data
func (tsr *Uint64) String() string {
	str := tsr.Label()
	sz := len(tsr.Values)
	if sz > 1000 {
		return str
	}
	var b strings.Builder
	b.WriteString(str)
	b.WriteString("\n")
	oddRow := true
	rows, cols, _, _ := Prjn2DShape(&tsr.Shape, oddRow)
	for r := 0; r < rows; r++ {
		rc, _ := Prjn2DCoords(&tsr.Shape, oddRow, r, 0)
		b.WriteString(fmt.Sprintf("%v: ", rc))
		for c := 0; c < cols; c++ {
			vl := Prjn2DValue(tsr, oddRow, r, c)
			b.WriteString(fmt.Sprintf("%7g ", vl))
		}
		b.WriteString("\n")
	}
	return b.String()
}

// ToArrow returns the apache arrow equivalent of the tensor
func (tsr *Uint64) ToArrow() *tensor.Uint64 {
	bld := array.NewUint64Builder(memory.DefaultAllocator)
	if tsr.Nulls != nil {
		bld.AppendValues(tsr.Values, tsr.Nulls.ToBools())
	} else {
		bld.AppendValues(tsr.Values, nil)
	}
	vec := bld.NewUint64Array()
	return tensor.NewUint64(vec.Data(), tsr.Shape64(), tsr.Strides64(), tsr.DimNames())
}

// FromArrow intializes this tensor from an arrow tensor of same type
// cpy = true means make a copy of the arrow data, otherwise it directly
// refers to its values slice -- we do not Retain() on that data so it is up
// to the go GC and / or your own memory management policies to ensure the data
// remains intact!
func (tsr *Uint64) FromArrow(arw *tensor.Uint64, cpy bool) {
	nms := make([]string, arw.NumDims()) // note: would be nice if it exposed DimNames()
	for i := range nms {
		nms[i] = arw.DimName(i)
	}
	tsr.SetShape64(arw.Shape(), arw.Strides(), nms)
	if cpy {
		vls := arw.Uint64Values()
		tsr.Values = make([]uint64, tsr.Len())
		copy(tsr.Values, vls)
	} else {
		tsr.Values = arw.Uint64Values()
	}
	// note: doesn't look like the Data() exposes the nulls themselves so it is not
	// clear we can copy the null values -- nor does it seem that the tensor class
	// exposes it either!  https://github.com/apache/arrow/issues/3496
	// nln := arw.Data().NullN()
	// if nln > 0 {
	// }
}

// Dims is the gonum/mat.Matrix interface method for returning the dimensionality of the
// 2D Matrix.  Assumes Row-major ordering and logs an error if NumDims < 2.
func (tsr *Uint64) Dims() (r, c int) {
	nd := tsr.NumDims()
	if nd < 2 {
		log.Println("etensor Dims gonum Matrix call made on Tensor with dims < 2")
		return 0, 0
	}
	return tsr.Dim(nd - 2), tsr.Dim(nd - 1)
}

// At is the gonum/mat.Matrix interface method for returning 2D matrix element at given
// row, column index.  Assumes Row-major ordering and logs an error if NumDims < 2.
func (tsr *Uint64) At(i, j int) float64 {
	nd := tsr.NumDims()
	if nd < 2 {
		log.Println("etensor Dims gonum Matrix call made on Tensor with dims < 2")
		return 0
	} else if nd == 2 {
		return tsr.FloatValue([]int{i, j})
	} else {
		ix := make([]int, nd)
		ix[nd-2] = i
		ix[nd-1] = j
		return tsr.FloatValue(ix)
	}
}

// T is the gonum/mat.Matrix transpose method.
// It performs an implicit transpose by returning the receiver inside a Transpose.
func (tsr *Uint64) T() mat.Matrix {
	return mat.Transpose{tsr}
}

// Symmetric is the gonum/mat.Matrix interface method for returning the dimensionality of a symmetric
// 2D Matrix.  Logs error if called on non-symmetric matrix.
func (tsr *Uint64) Symmetric() (r int) {
	nd := tsr.NumDims()
	if nd < 2 {
		log.Println("etensor Symmetric gonum Matrix call made on Tensor with dims < 2")
		return 0
	}
	if tsr.Dim(nd-2) != tsr.Dim(nd-1) {
		log.Println("etensor Symmatrics gonum Matrix call made on Tensor that is not symmetric")
		return 0
	}
	return tsr.Dim(nd - 1)
}

// SymmetricDim is the gonum/mat.Matrix interface method for returning the dimensionality of a symmetric
// 2D Matrix.  Logs error if called on non-symmetric matrix.
func (tsr *Uint64) SymmetricDim() int {
	nd := tsr.NumDims()
	if nd < 2 {
		log.Println("etensor Symmetric gonum Matrix call made on Tensor with dims < 2")
		return 0
	}
	if tsr.Dim(nd-2) != tsr.Dim(nd-1) {
		log.Println("etensor Symmetric gonum Matrix call made on Tensor that is not symmetric")
		return 0
	}
	return tsr.Dim(nd - 1)
}

// SetMetaData sets a key=value meta data (stored as a map[string]string).
// For TensorGrid display: top-zero=+/-, odd-row=+/-, image=+/-,
// min, max set fixed min / max values, background=color
func (tsr *Uint64) SetMetaData(key, val string) {
	if tsr.Meta == nil {
		tsr.Meta = make(map[string]string)
	}
	tsr.Meta[key] = val
}

// MetaData retrieves value of given key, bool = false if not set
func (tsr *Uint64) MetaData(key string) (string, bool) {
	if tsr.Meta == nil {
		return "", false
	}
	val, ok := tsr.Meta[key]
	return val, ok
}

// MetaDataMap returns the underlying map used for meta data
func (tsr *Uint64) MetaDataMap() map[string]string {
	return tsr.Meta
}

// CopyMetaData copies meta data from given source tensor
func (tsr *Uint64) CopyMetaData(frm Tensor) {
	fmap := frm.MetaDataMap()
	if len(fmap) == 0 {
		return
	}
	if tsr.Meta == nil {
		tsr.Meta = make(map[string]string)
	}
	for k, v := range fmap {
		tsr.Meta[k] = v
	}
}

// Int32 is an n-dim array of int32s.
type Int32 struct {
	Shape
	Values []int32
	Nulls  bitslice.Slice
	Meta   map[string]string
}

// NewInt32 returns a new n-dimensional array of int32s.
// If strides is nil, row-major strides will be inferred.
// If names is nil, a slice of empty strings will be created.
// Nulls are initialized to nil.
func NewInt32(shape, strides []int, names []string) *Int32 {
	tsr := &Int32{}
	tsr.SetShape(shape, strides, names)
	tsr.Values = make([]int32, tsr.Len())
	return tsr
}

// NewInt32Shape returns a new n-dimensional array of int32s.
// Using shape structure instead of separate slices, and optionally
// existing values if vals != nil (must be of proper length) -- we
// directly set our internal Values = vals, thereby sharing the same
// underlying data. Nulls are initialized to nil.
func NewInt32Shape(shape *Shape, vals []int32) *Int32 {
	tsr := &Int32{}
	tsr.CopyShape(shape)
	if vals != nil {
		if len(vals) != tsr.Len() {
			log.Printf("etensor.NewInt32Shape: length of provided vals: %d not proper length: %d", len(vals), tsr.Len())
			tsr.Values = make([]int32, tsr.Len())
		} else {
			tsr.Values = vals
		}
	} else {
		tsr.Values = make([]int32, tsr.Len())
	}
	return tsr
}

func (tsr *Int32) ShapeObj() *Shape       { return &tsr.Shape }
func (tsr *Int32) DataType() Type         { return INT32 }
func (tsr *Int32) Value(i []int) int32    { j := tsr.Offset(i); return tsr.Values[j] }
func (tsr *Int32) Value1D(i int) int32    { return tsr.Values[i] }
func (tsr *Int32) Set(i []int, val int32) { j := tsr.Offset(i); tsr.Values[j] = val }
func (tsr *Int32) Set1D(i int, val int32) { tsr.Values[i] = val }
func (tsr *Int32) AddScalar(i []int, val int32) int32 {
	j := tsr.Offset(i)
	tsr.Values[j] += val
	return tsr.Values[j]
}
func (tsr *Int32) MulScalar(i []int, val int32) int32 {
	j := tsr.Offset(i)
	tsr.Values[j] *= val
	return tsr.Values[j]
}

// IsNull returns true if the given index has been flagged as a Null
// (undefined, not present) value
func (tsr *Int32) IsNull(i []int) bool {
	if tsr.Nulls == nil {
		return false
	}
	j := tsr.Offset(i)
	return tsr.Nulls.Index(j)
}

// IsNull1D returns true if the given 1-dimensional index has been flagged as a Null
// (undefined, not present) value
func (tsr *Int32) IsNull1D(i int) bool {
	if tsr.Nulls == nil {
		return false
	}
	return tsr.Nulls.Index(i)
}

// SetNull sets whether given index has a null value or not.
// All values are assumed valid (non-Null) until marked otherwise, and calling
// this method creates a Null bitslice map if one has not already been set yet.
func (tsr *Int32) SetNull(i []int, nul bool) {
	if tsr.Nulls == nil {
		tsr.Nulls = bitslice.Make(tsr.Len(), 0)
	}
	j := tsr.Offset(i)
	tsr.Nulls.Set(j, nul)
}

// SetNull1D sets whether given 1-dimensional index has a null value or not.
// All values are assumed valid (non-Null) until marked otherwise, and calling
// this method creates a Null bitslice map if one has not already been set yet.
func (tsr *Int32) SetNull1D(i int, nul bool) {
	if tsr.Nulls == nil {
		tsr.Nulls = bitslice.Make(tsr.Len(), 0)
	}
	tsr.Nulls.Set(i, nul)
}

func (tsr *Int32) FloatValue(i []int) float64      { j := tsr.Offset(i); return float64(tsr.Values[j]) }
func (tsr *Int32) SetFloat(i []int, val float64) { j := tsr.Offset(i); tsr.Values[j] = int32(val) }

func (tsr *Int32) StringValue(i []int) string { j := tsr.Offset(i); return laser.ToString(tsr.Values[j]) }
func (tsr *Int32) SetString(i []int, val string) {
	if fv, err := strconv.ParseFloat(val, 64); err == nil {
		j := tsr.Offset(i)
		tsr.Values[j] = int32(fv)
	}
}

func (tsr *Int32) FloatValue1D(off int) float64      { return float64(tsr.Values[off]) }
func (tsr *Int32) SetFloat1D(off int, val float64) { tsr.Values[off] = int32(val) }

func (tsr *Int32) FloatValueRowCell(row, cell int) float64 {
	_, sz := tsr.RowCellSize()
	return float64(tsr.Values[row*sz+cell])
}
func (tsr *Int32) SetFloatRowCell(row, cell int, val float64) {
	_, sz := tsr.RowCellSize()
	tsr.Values[row*sz+cell] = int32(val)
}

// Floats sets []float64 slice of all elements in the tensor
// (length is ensured to be sufficient).
// This can be used for all of the gonum/floats methods
// for basic math, gonum/stats, etc.
func (tsr *Int32) Floats(flt *[]float64) {
	SetFloat64SliceLen(flt, len(tsr.Values))
	for j, vl := range tsr.Values {
		(*flt)[j] = float64(vl)
	}
}

// SetFloats sets tensor values from a []float64 slice (copies values).
func (tsr *Int32) SetFloats(vals []float64) {
	sz := min(len(tsr.Values), len(vals))
	for j := 0; j < sz; j++ {
		tsr.Values[j] = int32(vals[j])
	}
}

func (tsr *Int32) StringValue1D(off int) string { return laser.ToString(tsr.Values[off]) }
func (tsr *Int32) SetString1D(off int, val string) {
	if fv, err := strconv.ParseFloat(val, 64); err == nil {
		tsr.Values[off] = int32(fv)
	}
}

func (tsr *Int32) StringValueRowCell(row, cell int) string {
	_, sz := tsr.RowCellSize()
	return laser.ToString(tsr.Values[row*sz+cell])
}
func (tsr *Int32) SetStringRowCell(row, cell int, val string) {
	if fv, err := strconv.ParseFloat(val, 64); err == nil {
		_, sz := tsr.RowCellSize()
		tsr.Values[row*sz+cell] = int32(fv)
	}
}

// Range returns the min, max (and associated indexes, -1 = no values) for the tensor.
// This is needed for display and is thus in the core api in optimized form
// Other math operations can be done using gonum/floats package.
func (tsr *Int32) Range() (min, max float64, minIndex, maxIndex int) {
	minIndex = -1
	maxIndex = -1
	for j, vl := range tsr.Values {
		fv := float64(vl)
		if math.IsNaN(fv) {
			continue
		}
		if fv < min || minIndex < 0 {
			min = fv
			minIndex = j
		}
		if fv > max || maxIndex < 0 {
			max = fv
			maxIndex = j
		}
	}
	return
}

// Agg applies given aggregation function to each element in the tensor
// (automatically skips IsNull and NaN elements), using float64 conversions of the values.
// init is the initial value for the agg variable. returns final aggregate value
func (tsr *Int32) Agg(ini float64, fun AggFunc) float64 {
	ag := ini
	for j, vl := range tsr.Values {
		val := float64(vl)
		if !tsr.IsNull1D(j) && !math.IsNaN(val) {
			ag = fun(j, val, ag)
		}
	}
	return ag
}

// Eval applies given function to each element in the tensor (automatically
// skips IsNull and NaN elements), using float64 conversions of the values.
// Puts the results into given float64 slice, which is ensured to be of the proper length.
func (tsr *Int32) Eval(res *[]float64, fun EvalFunc) {
	ln := tsr.Len()
	if len(*res) != ln {
		*res = make([]float64, ln)
	}
	for j, vl := range tsr.Values {
		val := float64(vl)
		if !tsr.IsNull1D(j) && !math.IsNaN(val) {
			(*res)[j] = fun(j, val)
		}
	}
}

// SetFunc applies given function to each element in the tensor (automatically
// skips IsNull and NaN elements), using float64 conversions of the values.
// Writes the results back into the same tensor elements.
func (tsr *Int32) SetFunc(fun EvalFunc) {
	for j, vl := range tsr.Values {
		val := float64(vl)
		if !tsr.IsNull1D(j) && !math.IsNaN(val) {
			tsr.Values[j] = int32(fun(j, val))
		}
	}
}

// SetZeros is simple convenience function initialize all values to 0
func (tsr *Int32) SetZeros() {
	for j := range tsr.Values {
		tsr.Values[j] = 0
	}
}

// Clone clones this tensor, creating a duplicate copy of itself with its
// own separate memory representation of all the values, and returns
// that as a Tensor (which can be converted into the known type as needed).
func (tsr *Int32) Clone() Tensor {
	csr := NewInt32Shape(&tsr.Shape, nil)
	copy(csr.Values, tsr.Values)
	if tsr.Nulls != nil {
		csr.Nulls = tsr.Nulls.Clone()
	}
	return csr
}

// CopyFrom copies all avail values from other tensor into this tensor, with an
// optimized implementation if the other tensor is of the same type, and
// otherwise it goes through appropriate standard type.
// Copies Null state as well if present.
func (tsr *Int32) CopyFrom(frm Tensor) {
	if fsm, ok := frm.(*Int32); ok {
		copy(tsr.Values, fsm.Values)
		if fsm.Nulls != nil {
			if tsr.Nulls == nil {
				tsr.Nulls = bitslice.Make(tsr.Len(), 0)
			}
			copy(tsr.Nulls, fsm.Nulls)
		}
		return
	}
	sz := min(len(tsr.Values), frm.Len())
	for i := 0; i < sz; i++ {
		tsr.Values[i] = int32(frm.FloatValue1D(i))
		if frm.IsNull1D(i) {
			tsr.SetNull1D(i, true)
		}
	}
}

// CopyShapeFrom copies just the shape from given source tensor
// calling SetShape with the shape params from source (see for more docs).
func (tsr *Int32) CopyShapeFrom(frm Tensor) {
	tsr.SetShape(frm.Shapes(), frm.Strides(), frm.DimNames())
}

// CopyCellsFrom copies given range of values from other tensor into this tensor,
// using flat 1D indexes: to = starting index in this Tensor to start copying into,
// start = starting index on from Tensor to start copying from, and n = number of
// values to copy.  Uses an optimized implementation if the other tensor is
// of the same type, and otherwise it goes through appropriate standard type.
func (tsr *Int32) CopyCellsFrom(frm Tensor, to, start, n int) {
	if fsm, ok := frm.(*Int32); ok {
		for i := 0; i < n; i++ {
			tsr.Values[to+i] = fsm.Values[start+i]
			if fsm.IsNull1D(start + i) {
				tsr.SetNull1D(to+i, true)
			}
		}
		return
	}
	for i := 0; i < n; i++ {
		tsr.Values[to+i] = int32(frm.FloatValue1D(start + i))
		if frm.IsNull1D(start + i) {
			tsr.SetNull1D(to+i, true)
		}
	}
}

// SetShape sets the shape params, resizing backing storage appropriately
func (tsr *Int32) SetShape(shape, strides []int, names []string) {
	tsr.Shape.SetShape(shape, strides, names)
	nln := tsr.Len()
	if cap(tsr.Values) >= nln {
		tsr.Values = tsr.Values[0:nln]
	} else {
		nv := make([]int32, nln)
		copy(nv, tsr.Values)
		tsr.Values = nv
	}
	if tsr.Nulls != nil {
		tsr.Nulls.SetLen(nln)
	}
}

// SetNumRows sets the number of rows (outer-most dimension) in a RowMajor organized tensor.
func (tsr *Int32) SetNumRows(rows int) {
	if !tsr.IsRowMajor() {
		return
	}
	rows = max(1, rows) // must be > 0
	_, cells := tsr.RowCellSize()
	nln := rows * cells
	tsr.Shape.Shp[0] = rows
	if cap(tsr.Values) >= nln {
		tsr.Values = tsr.Values[0:nln]
	} else {
		nv := make([]int32, nln)
		copy(nv, tsr.Values)
		tsr.Values = nv
	}
	if tsr.Nulls != nil {
		tsr.Nulls.SetLen(nln)
	}
}

// SubSpace returns a new tensor with innermost subspace at given
// offset(s) in outermost dimension(s) (len(offs) < NumDims).
// Only valid for row or column major layouts.
// The new tensor points to the values of the this tensor (i.e., modifications
// will affect both), as its Values slice is a view onto the original (which
// is why only inner-most contiguous supsaces are supported).
// Use Clone() method to separate the two.
// Null value bits are NOT shared but are copied if present.
func (tsr *Int32) SubSpace(offs []int) Tensor {
	ss, _ := tsr.SubSpaceTry(offs)
	return ss
}

// SubSpaceTry returns a new tensor with innermost subspace at given
// offset(s) in outermost dimension(s) (len(offs) < NumDims).
// Try version returns an error message if the offs do not fit in tensor Shape.
// Only valid for row or column major layouts.
// The new tensor points to the values of the this tensor (i.e., modifications
// will affect both), as its Values slice is a view onto the original (which
// is why only inner-most contiguous supsaces are supported).
// Use Clone() method to separate the two.
// Null value bits are NOT shared but are copied if present.
func (tsr *Int32) SubSpaceTry(offs []int) (Tensor, error) {
	nd := tsr.NumDims()
	od := len(offs)
	if od >= nd {
		return nil, errors.New("SubSpace len(offsets) for outer dimensions was >= NumDims -- must be less")
	}
	id := nd - od
	if tsr.IsRowMajor() {
		stsr := &Int32{}
		stsr.SetShape(tsr.Shp[od:], nil, tsr.Nms[od:]) // row major def
		sti := make([]int, nd)
		copy(sti, offs)
		stoff := tsr.Offset(sti)
		sln := stsr.Len()
		stsr.Values = tsr.Values[stoff : stoff+sln]
		if tsr.Nulls != nil {
			stsr.Nulls = tsr.Nulls.SubSlice(stoff, stoff+sln)
		}
		return stsr, nil
	} else if tsr.IsColMajor() {
		stsr := &Int32{}
		stsr.SetShape(tsr.Shp[:id], nil, tsr.Nms[:id])
		stsr.Strd = ColMajorStrides(stsr.Shp)
		sti := make([]int, nd)
		for i := id; i < nd; i++ {
			sti[i] = offs[i-id]
		}
		stoff := tsr.Offset(sti)
		sln := stsr.Len()
		stsr.Values = tsr.Values[stoff : stoff+sln]
		if tsr.Nulls != nil {
			stsr.Nulls = tsr.Nulls.SubSlice(stoff, stoff+sln)
		}
		return stsr, nil
	}
	return nil, errors.New("SubSpace only valid for RowMajor or ColMajor tensors")
}

// Label satisfies the gi.Labeler interface for a summary description of the tensor
func (tsr *Int32) Label() string {
	return fmt.Sprintf("Int32: %s", tsr.Shape.String())
}

// String satisfies the fmt.Stringer interface for string of tensor data
func (tsr *Int32) String() string {
	str := tsr.Label()
	sz := len(tsr.Values)
	if sz > 1000 {
		return str
	}
	var b strings.Builder
	b.WriteString(str)
	b.WriteString("\n")
	oddRow := true
	rows, cols, _, _ := Prjn2DShape(&tsr.Shape, oddRow)
	for r := 0; r < rows; r++ {
		rc, _ := Prjn2DCoords(&tsr.Shape, oddRow, r, 0)
		b.WriteString(fmt.Sprintf("%v: ", rc))
		for c := 0; c < cols; c++ {
			vl := Prjn2DValue(tsr, oddRow, r, c)
			b.WriteString(fmt.Sprintf("%7g ", vl))
		}
		b.WriteString("\n")
	}
	return b.String()
}

// ToArrow returns the apache arrow equivalent of the tensor
func (tsr *Int32) ToArrow() *tensor.Int32 {
	bld := array.NewInt32Builder(memory.DefaultAllocator)
	if tsr.Nulls != nil {
		bld.AppendValues(tsr.Values, tsr.Nulls.ToBools())
	} else {
		bld.AppendValues(tsr.Values, nil)
	}
	vec := bld.NewInt32Array()
	return tensor.NewInt32(vec.Data(), tsr.Shape64(), tsr.Strides64(), tsr.DimNames())
}

// FromArrow intializes this tensor from an arrow tensor of same type
// cpy = true means make a copy of the arrow data, otherwise it directly
// refers to its values slice -- we do not Retain() on that data so it is up
// to the go GC and / or your own memory management policies to ensure the data
// remains intact!
func (tsr *Int32) FromArrow(arw *tensor.Int32, cpy bool) {
	nms := make([]string, arw.NumDims()) // note: would be nice if it exposed DimNames()
	for i := range nms {
		nms[i] = arw.DimName(i)
	}
	tsr.SetShape64(arw.Shape(), arw.Strides(), nms)
	if cpy {
		vls := arw.Int32Values()
		tsr.Values = make([]int32, tsr.Len())
		copy(tsr.Values, vls)
	} else {
		tsr.Values = arw.Int32Values()
	}
	// note: doesn't look like the Data() exposes the nulls themselves so it is not
	// clear we can copy the null values -- nor does it seem that the tensor class
	// exposes it either!  https://github.com/apache/arrow/issues/3496
	// nln := arw.Data().NullN()
	// if nln > 0 {
	// }
}

// Dims is the gonum/mat.Matrix interface method for returning the dimensionality of the
// 2D Matrix.  Assumes Row-major ordering and logs an error if NumDims < 2.
func (tsr *Int32) Dims() (r, c int) {
	nd := tsr.NumDims()
	if nd < 2 {
		log.Println("etensor Dims gonum Matrix call made on Tensor with dims < 2")
		return 0, 0
	}
	return tsr.Dim(nd - 2), tsr.Dim(nd - 1)
}

// At is the gonum/mat.Matrix interface method for returning 2D matrix element at given
// row, column index.  Assumes Row-major ordering and logs an error if NumDims < 2.
func (tsr *Int32) At(i, j int) float64 {
	nd := tsr.NumDims()
	if nd < 2 {
		log.Println("etensor Dims gonum Matrix call made on Tensor with dims < 2")
		return 0
	} else if nd == 2 {
		return tsr.FloatValue([]int{i, j})
	} else {
		ix := make([]int, nd)
		ix[nd-2] = i
		ix[nd-1] = j
		return tsr.FloatValue(ix)
	}
}

// T is the gonum/mat.Matrix transpose method.
// It performs an implicit transpose by returning the receiver inside a Transpose.
func (tsr *Int32) T() mat.Matrix {
	return mat.Transpose{tsr}
}

// Symmetric is the gonum/mat.Matrix interface method for returning the dimensionality of a symmetric
// 2D Matrix.  Logs error if called on non-symmetric matrix.
func (tsr *Int32) Symmetric() (r int) {
	nd := tsr.NumDims()
	if nd < 2 {
		log.Println("etensor Symmetric gonum Matrix call made on Tensor with dims < 2")
		return 0
	}
	if tsr.Dim(nd-2) != tsr.Dim(nd-1) {
		log.Println("etensor Symmatrics gonum Matrix call made on Tensor that is not symmetric")
		return 0
	}
	return tsr.Dim(nd - 1)
}

// SymmetricDim is the gonum/mat.Matrix interface method for returning the dimensionality of a symmetric
// 2D Matrix.  Logs error if called on non-symmetric matrix.
func (tsr *Int32) SymmetricDim() int {
	nd := tsr.NumDims()
	if nd < 2 {
		log.Println("etensor Symmetric gonum Matrix call made on Tensor with dims < 2")
		return 0
	}
	if tsr.Dim(nd-2) != tsr.Dim(nd-1) {
		log.Println("etensor Symmetric gonum Matrix call made on Tensor that is not symmetric")
		return 0
	}
	return tsr.Dim(nd - 1)
}

// SetMetaData sets a key=value meta data (stored as a map[string]string).
// For TensorGrid display: top-zero=+/-, odd-row=+/-, image=+/-,
// min, max set fixed min / max values, background=color
func (tsr *Int32) SetMetaData(key, val string) {
	if tsr.Meta == nil {
		tsr.Meta = make(map[string]string)
	}
	tsr.Meta[key] = val
}

// MetaData retrieves value of given key, bool = false if not set
func (tsr *Int32) MetaData(key string) (string, bool) {
	if tsr.Meta == nil {
		return "", false
	}
	val, ok := tsr.Meta[key]
	return val, ok
}

// MetaDataMap returns the underlying map used for meta data
func (tsr *Int32) MetaDataMap() map[string]string {
	return tsr.Meta
}

// CopyMetaData copies meta data from given source tensor
func (tsr *Int32) CopyMetaData(frm Tensor) {
	fmap := frm.MetaDataMap()
	if len(fmap) == 0 {
		return
	}
	if tsr.Meta == nil {
		tsr.Meta = make(map[string]string)
	}
	for k, v := range fmap {
		tsr.Meta[k] = v
	}
}

// Uint32 is an n-dim array of uint32s.
type Uint32 struct {
	Shape
	Values []uint32
	Nulls  bitslice.Slice
	Meta   map[string]string
}

// NewUint32 returns a new n-dimensional array of uint32s.
// If strides is nil, row-major strides will be inferred.
// If names is nil, a slice of empty strings will be created.
// Nulls are initialized to nil.
func NewUint32(shape, strides []int, names []string) *Uint32 {
	tsr := &Uint32{}
	tsr.SetShape(shape, strides, names)
	tsr.Values = make([]uint32, tsr.Len())
	return tsr
}

// NewUint32Shape returns a new n-dimensional array of uint32s.
// Using shape structure instead of separate slices, and optionally
// existing values if vals != nil (must be of proper length) -- we
// directly set our internal Values = vals, thereby sharing the same
// underlying data. Nulls are initialized to nil.
func NewUint32Shape(shape *Shape, vals []uint32) *Uint32 {
	tsr := &Uint32{}
	tsr.CopyShape(shape)
	if vals != nil {
		if len(vals) != tsr.Len() {
			log.Printf("etensor.NewUint32Shape: length of provided vals: %d not proper length: %d", len(vals), tsr.Len())
			tsr.Values = make([]uint32, tsr.Len())
		} else {
			tsr.Values = vals
		}
	} else {
		tsr.Values = make([]uint32, tsr.Len())
	}
	return tsr
}

func (tsr *Uint32) ShapeObj() *Shape        { return &tsr.Shape }
func (tsr *Uint32) DataType() Type          { return UINT32 }
func (tsr *Uint32) Value(i []int) uint32    { j := tsr.Offset(i); return tsr.Values[j] }
func (tsr *Uint32) Value1D(i int) uint32    { return tsr.Values[i] }
func (tsr *Uint32) Set(i []int, val uint32) { j := tsr.Offset(i); tsr.Values[j] = val }
func (tsr *Uint32) Set1D(i int, val uint32) { tsr.Values[i] = val }
func (tsr *Uint32) AddScalar(i []int, val uint32) uint32 {
	j := tsr.Offset(i)
	tsr.Values[j] += val
	return tsr.Values[j]
}
func (tsr *Uint32) MulScalar(i []int, val uint32) uint32 {
	j := tsr.Offset(i)
	tsr.Values[j] *= val
	return tsr.Values[j]
}

// IsNull returns true if the given index has been flagged as a Null
// (undefined, not present) value
func (tsr *Uint32) IsNull(i []int) bool {
	if tsr.Nulls == nil {
		return false
	}
	j := tsr.Offset(i)
	return tsr.Nulls.Index(j)
}

// IsNull1D returns true if the given 1-dimensional index has been flagged as a Null
// (undefined, not present) value
func (tsr *Uint32) IsNull1D(i int) bool {
	if tsr.Nulls == nil {
		return false
	}
	return tsr.Nulls.Index(i)
}

// SetNull sets whether given index has a null value or not.
// All values are assumed valid (non-Null) until marked otherwise, and calling
// this method creates a Null bitslice map if one has not already been set yet.
func (tsr *Uint32) SetNull(i []int, nul bool) {
	if tsr.Nulls == nil {
		tsr.Nulls = bitslice.Make(tsr.Len(), 0)
	}
	j := tsr.Offset(i)
	tsr.Nulls.Set(j, nul)
}

// SetNull1D sets whether given 1-dimensional index has a null value or not.
// All values are assumed valid (non-Null) until marked otherwise, and calling
// this method creates a Null bitslice map if one has not already been set yet.
func (tsr *Uint32) SetNull1D(i int, nul bool) {
	if tsr.Nulls == nil {
		tsr.Nulls = bitslice.Make(tsr.Len(), 0)
	}
	tsr.Nulls.Set(i, nul)
}

func (tsr *Uint32) FloatValue(i []int) float64      { j := tsr.Offset(i); return float64(tsr.Values[j]) }
func (tsr *Uint32) SetFloat(i []int, val float64) { j := tsr.Offset(i); tsr.Values[j] = uint32(val) }

func (tsr *Uint32) StringValue(i []int) string {
	j := tsr.Offset(i)
	return laser.ToString(tsr.Values[j])
}
func (tsr *Uint32) SetString(i []int, val string) {
	if fv, err := strconv.ParseFloat(val, 64); err == nil {
		j := tsr.Offset(i)
		tsr.Values[j] = uint32(fv)
	}
}

func (tsr *Uint32) FloatValue1D(off int) float64      { return float64(tsr.Values[off]) }
func (tsr *Uint32) SetFloat1D(off int, val float64) { tsr.Values[off] = uint32(val) }

func (tsr *Uint32) FloatValueRowCell(row, cell int) float64 {
	_, sz := tsr.RowCellSize()
	return float64(tsr.Values[row*sz+cell])
}
func (tsr *Uint32) SetFloatRowCell(row, cell int, val float64) {
	_, sz := tsr.RowCellSize()
	tsr.Values[row*sz+cell] = uint32(val)
}

// Floats sets []float64 slice of all elements in the tensor
// (length is ensured to be sufficient).
// This can be used for all of the gonum/floats methods
// for basic math, gonum/stats, etc.
func (tsr *Uint32) Floats(flt *[]float64) {
	SetFloat64SliceLen(flt, len(tsr.Values))
	for j, vl := range tsr.Values {
		(*flt)[j] = float64(vl)
	}
}

// SetFloats sets tensor values from a []float64 slice (copies values).
func (tsr *Uint32) SetFloats(vals []float64) {
	sz := min(len(tsr.Values), len(vals))
	for j := 0; j < sz; j++ {
		tsr.Values[j] = uint32(vals[j])
	}
}

func (tsr *Uint32) StringValue1D(off int) string { return laser.ToString(tsr.Values[off]) }
func (tsr *Uint32) SetString1D(off int, val string) {
	if fv, err := strconv.ParseFloat(val, 64); err == nil {
		tsr.Values[off] = uint32(fv)
	}
}

func (tsr *Uint32) StringValueRowCell(row, cell int) string {
	_, sz := tsr.RowCellSize()
	return laser.ToString(tsr.Values[row*sz+cell])
}
func (tsr *Uint32) SetStringRowCell(row, cell int, val string) {
	if fv, err := strconv.ParseFloat(val, 64); err == nil {
		_, sz := tsr.RowCellSize()
		tsr.Values[row*sz+cell] = uint32(fv)
	}
}

// Range returns the min, max (and associated indexes, -1 = no values) for the tensor.
// This is needed for display and is thus in the core api in optimized form
// Other math operations can be done using gonum/floats package.
func (tsr *Uint32) Range() (min, max float64, minIndex, maxIndex int) {
	minIndex = -1
	maxIndex = -1
	for j, vl := range tsr.Values {
		fv := float64(vl)
		if math.IsNaN(fv) {
			continue
		}
		if fv < min || minIndex < 0 {
			min = fv
			minIndex = j
		}
		if fv > max || maxIndex < 0 {
			max = fv
			maxIndex = j
		}
	}
	return
}

// Agg applies given aggregation function to each element in the tensor
// (automatically skips IsNull and NaN elements), using float64 conversions of the values.
// init is the initial value for the agg variable. returns final aggregate value
func (tsr *Uint32) Agg(ini float64, fun AggFunc) float64 {
	ag := ini
	for j, vl := range tsr.Values {
		val := float64(vl)
		if !tsr.IsNull1D(j) && !math.IsNaN(val) {
			ag = fun(j, val, ag)
		}
	}
	return ag
}

// Eval applies given function to each element in the tensor (automatically
// skips IsNull and NaN elements), using float64 conversions of the values.
// Puts the results into given float64 slice, which is ensured to be of the proper length.
func (tsr *Uint32) Eval(res *[]float64, fun EvalFunc) {
	ln := tsr.Len()
	if len(*res) != ln {
		*res = make([]float64, ln)
	}
	for j, vl := range tsr.Values {
		val := float64(vl)
		if !tsr.IsNull1D(j) && !math.IsNaN(val) {
			(*res)[j] = fun(j, val)
		}
	}
}

// SetFunc applies given function to each element in the tensor (automatically
// skips IsNull and NaN elements), using float64 conversions of the values.
// Writes the results back into the same tensor elements.
func (tsr *Uint32) SetFunc(fun EvalFunc) {
	for j, vl := range tsr.Values {
		val := float64(vl)
		if !tsr.IsNull1D(j) && !math.IsNaN(val) {
			tsr.Values[j] = uint32(fun(j, val))
		}
	}
}

// SetZeros is simple convenience function initialize all values to 0
func (tsr *Uint32) SetZeros() {
	for j := range tsr.Values {
		tsr.Values[j] = 0
	}
}

// Clone clones this tensor, creating a duplicate copy of itself with its
// own separate memory representation of all the values, and returns
// that as a Tensor (which can be converted into the known type as needed).
func (tsr *Uint32) Clone() Tensor {
	csr := NewUint32Shape(&tsr.Shape, nil)
	copy(csr.Values, tsr.Values)
	if tsr.Nulls != nil {
		csr.Nulls = tsr.Nulls.Clone()
	}
	return csr
}

// CopyFrom copies all avail values from other tensor into this tensor, with an
// optimized implementation if the other tensor is of the same type, and
// otherwise it goes through appropriate standard type.
// Copies Null state as well if present.
func (tsr *Uint32) CopyFrom(frm Tensor) {
	if fsm, ok := frm.(*Uint32); ok {
		copy(tsr.Values, fsm.Values)
		if fsm.Nulls != nil {
			if tsr.Nulls == nil {
				tsr.Nulls = bitslice.Make(tsr.Len(), 0)
			}
			copy(tsr.Nulls, fsm.Nulls)
		}
		return
	}
	sz := min(len(tsr.Values), frm.Len())
	for i := 0; i < sz; i++ {
		tsr.Values[i] = uint32(frm.FloatValue1D(i))
		if frm.IsNull1D(i) {
			tsr.SetNull1D(i, true)
		}
	}
}

// CopyShapeFrom copies just the shape from given source tensor
// calling SetShape with the shape params from source (see for more docs).
func (tsr *Uint32) CopyShapeFrom(frm Tensor) {
	tsr.SetShape(frm.Shapes(), frm.Strides(), frm.DimNames())
}

// CopyCellsFrom copies given range of values from other tensor into this tensor,
// using flat 1D indexes: to = starting index in this Tensor to start copying into,
// start = starting index on from Tensor to start copying from, and n = number of
// values to copy.  Uses an optimized implementation if the other tensor is
// of the same type, and otherwise it goes through appropriate standard type.
func (tsr *Uint32) CopyCellsFrom(frm Tensor, to, start, n int) {
	if fsm, ok := frm.(*Uint32); ok {
		for i := 0; i < n; i++ {
			tsr.Values[to+i] = fsm.Values[start+i]
			if fsm.IsNull1D(start + i) {
				tsr.SetNull1D(to+i, true)
			}
		}
		return
	}
	for i := 0; i < n; i++ {
		tsr.Values[to+i] = uint32(frm.FloatValue1D(start + i))
		if frm.IsNull1D(start + i) {
			tsr.SetNull1D(to+i, true)
		}
	}
}

// SetShape sets the shape params, resizing backing storage appropriately
func (tsr *Uint32) SetShape(shape, strides []int, names []string) {
	tsr.Shape.SetShape(shape, strides, names)
	nln := tsr.Len()
	if cap(tsr.Values) >= nln {
		tsr.Values = tsr.Values[0:nln]
	} else {
		nv := make([]uint32, nln)
		copy(nv, tsr.Values)
		tsr.Values = nv
	}
	if tsr.Nulls != nil {
		tsr.Nulls.SetLen(nln)
	}
}

// SetNumRows sets the number of rows (outer-most dimension) in a RowMajor organized tensor.
func (tsr *Uint32) SetNumRows(rows int) {
	if !tsr.IsRowMajor() {
		return
	}
	rows = max(1, rows) // must be > 0
	_, cells := tsr.RowCellSize()
	nln := rows * cells
	tsr.Shape.Shp[0] = rows
	if cap(tsr.Values) >= nln {
		tsr.Values = tsr.Values[0:nln]
	} else {
		nv := make([]uint32, nln)
		copy(nv, tsr.Values)
		tsr.Values = nv
	}
	if tsr.Nulls != nil {
		tsr.Nulls.SetLen(nln)
	}
}

// SubSpace returns a new tensor with innermost subspace at given
// offset(s) in outermost dimension(s) (len(offs) < NumDims).
// Only valid for row or column major layouts.
// The new tensor points to the values of the this tensor (i.e., modifications
// will affect both), as its Values slice is a view onto the original (which
// is why only inner-most contiguous supsaces are supported).
// Use Clone() method to separate the two.
// Null value bits are NOT shared but are copied if present.
func (tsr *Uint32) SubSpace(offs []int) Tensor {
	ss, _ := tsr.SubSpaceTry(offs)
	return ss
}

// SubSpaceTry returns a new tensor with innermost subspace at given
// offset(s) in outermost dimension(s) (len(offs) < NumDims).
// Try version returns an error message if the offs do not fit in tensor Shape.
// Only valid for row or column major layouts.
// The new tensor points to the values of the this tensor (i.e., modifications
// will affect both), as its Values slice is a view onto the original (which
// is why only inner-most contiguous supsaces are supported).
// Use Clone() method to separate the two.
// Null value bits are NOT shared but are copied if present.
func (tsr *Uint32) SubSpaceTry(offs []int) (Tensor, error) {
	nd := tsr.NumDims()
	od := len(offs)
	if od >= nd {
		return nil, errors.New("SubSpace len(offsets) for outer dimensions was >= NumDims -- must be less")
	}
	id := nd - od
	if tsr.IsRowMajor() {
		stsr := &Uint32{}
		stsr.SetShape(tsr.Shp[od:], nil, tsr.Nms[od:]) // row major def
		sti := make([]int, nd)
		copy(sti, offs)
		stoff := tsr.Offset(sti)
		sln := stsr.Len()
		stsr.Values = tsr.Values[stoff : stoff+sln]
		if tsr.Nulls != nil {
			stsr.Nulls = tsr.Nulls.SubSlice(stoff, stoff+sln)
		}
		return stsr, nil
	} else if tsr.IsColMajor() {
		stsr := &Uint32{}
		stsr.SetShape(tsr.Shp[:id], nil, tsr.Nms[:id])
		stsr.Strd = ColMajorStrides(stsr.Shp)
		sti := make([]int, nd)
		for i := id; i < nd; i++ {
			sti[i] = offs[i-id]
		}
		stoff := tsr.Offset(sti)
		sln := stsr.Len()
		stsr.Values = tsr.Values[stoff : stoff+sln]
		if tsr.Nulls != nil {
			stsr.Nulls = tsr.Nulls.SubSlice(stoff, stoff+sln)
		}
		return stsr, nil
	}
	return nil, errors.New("SubSpace only valid for RowMajor or ColMajor tensors")
}

// Label satisfies the gi.Labeler interface for a summary description of the tensor
func (tsr *Uint32) Label() string {
	return fmt.Sprintf("Uint32: %s", tsr.Shape.String())
}

// String satisfies the fmt.Stringer interface for string of tensor data
func (tsr *Uint32) String() string {
	str := tsr.Label()
	sz := len(tsr.Values)
	if sz > 1000 {
		return str
	}
	var b strings.Builder
	b.WriteString(str)
	b.WriteString("\n")
	oddRow := true
	rows, cols, _, _ := Prjn2DShape(&tsr.Shape, oddRow)
	for r := 0; r < rows; r++ {
		rc, _ := Prjn2DCoords(&tsr.Shape, oddRow, r, 0)
		b.WriteString(fmt.Sprintf("%v: ", rc))
		for c := 0; c < cols; c++ {
			vl := Prjn2DValue(tsr, oddRow, r, c)
			b.WriteString(fmt.Sprintf("%7g ", vl))
		}
		b.WriteString("\n")
	}
	return b.String()
}

// ToArrow returns the apache arrow equivalent of the tensor
func (tsr *Uint32) ToArrow() *tensor.Uint32 {
	bld := array.NewUint32Builder(memory.DefaultAllocator)
	if tsr.Nulls != nil {
		bld.AppendValues(tsr.Values, tsr.Nulls.ToBools())
	} else {
		bld.AppendValues(tsr.Values, nil)
	}
	vec := bld.NewUint32Array()
	return tensor.NewUint32(vec.Data(), tsr.Shape64(), tsr.Strides64(), tsr.DimNames())
}

// FromArrow intializes this tensor from an arrow tensor of same type
// cpy = true means make a copy of the arrow data, otherwise it directly
// refers to its values slice -- we do not Retain() on that data so it is up
// to the go GC and / or your own memory management policies to ensure the data
// remains intact!
func (tsr *Uint32) FromArrow(arw *tensor.Uint32, cpy bool) {
	nms := make([]string, arw.NumDims()) // note: would be nice if it exposed DimNames()
	for i := range nms {
		nms[i] = arw.DimName(i)
	}
	tsr.SetShape64(arw.Shape(), arw.Strides(), nms)
	if cpy {
		vls := arw.Uint32Values()
		tsr.Values = make([]uint32, tsr.Len())
		copy(tsr.Values, vls)
	} else {
		tsr.Values = arw.Uint32Values()
	}
	// note: doesn't look like the Data() exposes the nulls themselves so it is not
	// clear we can copy the null values -- nor does it seem that the tensor class
	// exposes it either!  https://github.com/apache/arrow/issues/3496
	// nln := arw.Data().NullN()
	// if nln > 0 {
	// }
}

// Dims is the gonum/mat.Matrix interface method for returning the dimensionality of the
// 2D Matrix.  Assumes Row-major ordering and logs an error if NumDims < 2.
func (tsr *Uint32) Dims() (r, c int) {
	nd := tsr.NumDims()
	if nd < 2 {
		log.Println("etensor Dims gonum Matrix call made on Tensor with dims < 2")
		return 0, 0
	}
	return tsr.Dim(nd - 2), tsr.Dim(nd - 1)
}

// At is the gonum/mat.Matrix interface method for returning 2D matrix element at given
// row, column index.  Assumes Row-major ordering and logs an error if NumDims < 2.
func (tsr *Uint32) At(i, j int) float64 {
	nd := tsr.NumDims()
	if nd < 2 {
		log.Println("etensor Dims gonum Matrix call made on Tensor with dims < 2")
		return 0
	} else if nd == 2 {
		return tsr.FloatValue([]int{i, j})
	} else {
		ix := make([]int, nd)
		ix[nd-2] = i
		ix[nd-1] = j
		return tsr.FloatValue(ix)
	}
}

// T is the gonum/mat.Matrix transpose method.
// It performs an implicit transpose by returning the receiver inside a Transpose.
func (tsr *Uint32) T() mat.Matrix {
	return mat.Transpose{tsr}
}

// Symmetric is the gonum/mat.Matrix interface method for returning the dimensionality of a symmetric
// 2D Matrix.  Logs error if called on non-symmetric matrix.
func (tsr *Uint32) Symmetric() (r int) {
	nd := tsr.NumDims()
	if nd < 2 {
		log.Println("etensor Symmetric gonum Matrix call made on Tensor with dims < 2")
		return 0
	}
	if tsr.Dim(nd-2) != tsr.Dim(nd-1) {
		log.Println("etensor Symmatrics gonum Matrix call made on Tensor that is not symmetric")
		return 0
	}
	return tsr.Dim(nd - 1)
}

// SymmetricDim is the gonum/mat.Matrix interface method for returning the dimensionality of a symmetric
// 2D Matrix.  Logs error if called on non-symmetric matrix.
func (tsr *Uint32) SymmetricDim() int {
	nd := tsr.NumDims()
	if nd < 2 {
		log.Println("etensor Symmetric gonum Matrix call made on Tensor with dims < 2")
		return 0
	}
	if tsr.Dim(nd-2) != tsr.Dim(nd-1) {
		log.Println("etensor Symmetric gonum Matrix call made on Tensor that is not symmetric")
		return 0
	}
	return tsr.Dim(nd - 1)
}

// SetMetaData sets a key=value meta data (stored as a map[string]string).
// For TensorGrid display: top-zero=+/-, odd-row=+/-, image=+/-,
// min, max set fixed min / max values, background=color
func (tsr *Uint32) SetMetaData(key, val string) {
	if tsr.Meta == nil {
		tsr.Meta = make(map[string]string)
	}
	tsr.Meta[key] = val
}

// MetaData retrieves value of given key, bool = false if not set
func (tsr *Uint32) MetaData(key string) (string, bool) {
	if tsr.Meta == nil {
		return "", false
	}
	val, ok := tsr.Meta[key]
	return val, ok
}

// MetaDataMap returns the underlying map used for meta data
func (tsr *Uint32) MetaDataMap() map[string]string {
	return tsr.Meta
}

// CopyMetaData copies meta data from given source tensor
func (tsr *Uint32) CopyMetaData(frm Tensor) {
	fmap := frm.MetaDataMap()
	if len(fmap) == 0 {
		return
	}
	if tsr.Meta == nil {
		tsr.Meta = make(map[string]string)
	}
	for k, v := range fmap {
		tsr.Meta[k] = v
	}
}

// Float32 is an n-dim array of float32s.
type Float32 struct {
	Shape
	Values []float32
	Nulls  bitslice.Slice
	Meta   map[string]string
}

// NewFloat32 returns a new n-dimensional array of float32s.
// If strides is nil, row-major strides will be inferred.
// If names is nil, a slice of empty strings will be created.
// Nulls are initialized to nil.
func NewFloat32(shape, strides []int, names []string) *Float32 {
	tsr := &Float32{}
	tsr.SetShape(shape, strides, names)
	tsr.Values = make([]float32, tsr.Len())
	return tsr
}

// NewFloat32Shape returns a new n-dimensional array of float32s.
// Using shape structure instead of separate slices, and optionally
// existing values if vals != nil (must be of proper length) -- we
// directly set our internal Values = vals, thereby sharing the same
// underlying data. Nulls are initialized to nil.
func NewFloat32Shape(shape *Shape, vals []float32) *Float32 {
	tsr := &Float32{}
	tsr.CopyShape(shape)
	if vals != nil {
		if len(vals) != tsr.Len() {
			log.Printf("etensor.NewFloat32Shape: length of provided vals: %d not proper length: %d", len(vals), tsr.Len())
			tsr.Values = make([]float32, tsr.Len())
		} else {
			tsr.Values = vals
		}
	} else {
		tsr.Values = make([]float32, tsr.Len())
	}
	return tsr
}

func (tsr *Float32) ShapeObj() *Shape         { return &tsr.Shape }
func (tsr *Float32) DataType() Type           { return FLOAT32 }
func (tsr *Float32) Value(i []int) float32    { j := tsr.Offset(i); return tsr.Values[j] }
func (tsr *Float32) Value1D(i int) float32    { return tsr.Values[i] }
func (tsr *Float32) Set(i []int, val float32) { j := tsr.Offset(i); tsr.Values[j] = val }
func (tsr *Float32) Set1D(i int, val float32) { tsr.Values[i] = val }
func (tsr *Float32) AddScalar(i []int, val float32) float32 {
	j := tsr.Offset(i)
	tsr.Values[j] += val
	return tsr.Values[j]
}
func (tsr *Float32) MulScalar(i []int, val float32) float32 {
	j := tsr.Offset(i)
	tsr.Values[j] *= val
	return tsr.Values[j]
}

// IsNull returns true if the given index has been flagged as a Null
// (undefined, not present) value
func (tsr *Float32) IsNull(i []int) bool {
	if tsr.Nulls == nil {
		return false
	}
	j := tsr.Offset(i)
	return tsr.Nulls.Index(j)
}

// IsNull1D returns true if the given 1-dimensional index has been flagged as a Null
// (undefined, not present) value
func (tsr *Float32) IsNull1D(i int) bool {
	if tsr.Nulls == nil {
		return false
	}
	return tsr.Nulls.Index(i)
}

// SetNull sets whether given index has a null value or not.
// All values are assumed valid (non-Null) until marked otherwise, and calling
// this method creates a Null bitslice map if one has not already been set yet.
func (tsr *Float32) SetNull(i []int, nul bool) {
	if tsr.Nulls == nil {
		tsr.Nulls = bitslice.Make(tsr.Len(), 0)
	}
	j := tsr.Offset(i)
	tsr.Nulls.Set(j, nul)
}

// SetNull1D sets whether given 1-dimensional index has a null value or not.
// All values are assumed valid (non-Null) until marked otherwise, and calling
// this method creates a Null bitslice map if one has not already been set yet.
func (tsr *Float32) SetNull1D(i int, nul bool) {
	if tsr.Nulls == nil {
		tsr.Nulls = bitslice.Make(tsr.Len(), 0)
	}
	tsr.Nulls.Set(i, nul)
}

func (tsr *Float32) FloatValue(i []int) float64      { j := tsr.Offset(i); return float64(tsr.Values[j]) }
func (tsr *Float32) SetFloat(i []int, val float64) { j := tsr.Offset(i); tsr.Values[j] = float32(val) }

func (tsr *Float32) StringValue(i []int) string {
	j := tsr.Offset(i)
	return laser.ToString(tsr.Values[j])
}
func (tsr *Float32) SetString(i []int, val string) {
	if fv, err := strconv.ParseFloat(val, 64); err == nil {
		j := tsr.Offset(i)
		tsr.Values[j] = float32(fv)
	}
}

func (tsr *Float32) FloatValue1D(off int) float64      { return float64(tsr.Values[off]) }
func (tsr *Float32) SetFloat1D(off int, val float64) { tsr.Values[off] = float32(val) }

func (tsr *Float32) FloatValueRowCell(row, cell int) float64 {
	_, sz := tsr.RowCellSize()
	return float64(tsr.Values[row*sz+cell])
}
func (tsr *Float32) SetFloatRowCell(row, cell int, val float64) {
	_, sz := tsr.RowCellSize()
	tsr.Values[row*sz+cell] = float32(val)
}

// Floats sets []float64 slice of all elements in the tensor
// (length is ensured to be sufficient).
// This can be used for all of the gonum/floats methods
// for basic math, gonum/stats, etc.
func (tsr *Float32) Floats(flt *[]float64) {
	SetFloat64SliceLen(flt, len(tsr.Values))
	for j, vl := range tsr.Values {
		(*flt)[j] = float64(vl)
	}
}

// SetFloats sets tensor values from a []float64 slice (copies values).
func (tsr *Float32) SetFloats(vals []float64) {
	sz := min(len(tsr.Values), len(vals))
	for j := 0; j < sz; j++ {
		tsr.Values[j] = float32(vals[j])
	}
}

func (tsr *Float32) StringValue1D(off int) string { return laser.ToString(tsr.Values[off]) }
func (tsr *Float32) SetString1D(off int, val string) {
	if fv, err := strconv.ParseFloat(val, 64); err == nil {
		tsr.Values[off] = float32(fv)
	}
}

func (tsr *Float32) StringValueRowCell(row, cell int) string {
	_, sz := tsr.RowCellSize()
	return laser.ToString(tsr.Values[row*sz+cell])
}
func (tsr *Float32) SetStringRowCell(row, cell int, val string) {
	if fv, err := strconv.ParseFloat(val, 64); err == nil {
		_, sz := tsr.RowCellSize()
		tsr.Values[row*sz+cell] = float32(fv)
	}
}

// Range returns the min, max (and associated indexes, -1 = no values) for the tensor.
// This is needed for display and is thus in the core api in optimized form
// Other math operations can be done using gonum/floats package.
func (tsr *Float32) Range() (min, max float64, minIndex, maxIndex int) {
	minIndex = -1
	maxIndex = -1
	for j, vl := range tsr.Values {
		fv := float64(vl)
		if math.IsNaN(fv) {
			continue
		}
		if fv < min || minIndex < 0 {
			min = fv
			minIndex = j
		}
		if fv > max || maxIndex < 0 {
			max = fv
			maxIndex = j
		}
	}
	return
}

// Agg applies given aggregation function to each element in the tensor
// (automatically skips IsNull and NaN elements), using float64 conversions of the values.
// init is the initial value for the agg variable. returns final aggregate value
func (tsr *Float32) Agg(ini float64, fun AggFunc) float64 {
	ag := ini
	for j, vl := range tsr.Values {
		val := float64(vl)
		if !tsr.IsNull1D(j) && !math.IsNaN(val) {
			ag = fun(j, val, ag)
		}
	}
	return ag
}

// Eval applies given function to each element in the tensor (automatically
// skips IsNull and NaN elements), using float64 conversions of the values.
// Puts the results into given float64 slice, which is ensured to be of the proper length.
func (tsr *Float32) Eval(res *[]float64, fun EvalFunc) {
	ln := tsr.Len()
	if len(*res) != ln {
		*res = make([]float64, ln)
	}
	for j, vl := range tsr.Values {
		val := float64(vl)
		if !tsr.IsNull1D(j) && !math.IsNaN(val) {
			(*res)[j] = fun(j, val)
		}
	}
}

// SetFunc applies given function to each element in the tensor (automatically
// skips IsNull and NaN elements), using float64 conversions of the values.
// Writes the results back into the same tensor elements.
func (tsr *Float32) SetFunc(fun EvalFunc) {
	for j, vl := range tsr.Values {
		val := float64(vl)
		if !tsr.IsNull1D(j) && !math.IsNaN(val) {
			tsr.Values[j] = float32(fun(j, val))
		}
	}
}

// SetZeros is simple convenience function initialize all values to 0
func (tsr *Float32) SetZeros() {
	for j := range tsr.Values {
		tsr.Values[j] = 0
	}
}

// Clone clones this tensor, creating a duplicate copy of itself with its
// own separate memory representation of all the values, and returns
// that as a Tensor (which can be converted into the known type as needed).
func (tsr *Float32) Clone() Tensor {
	csr := NewFloat32Shape(&tsr.Shape, nil)
	copy(csr.Values, tsr.Values)
	if tsr.Nulls != nil {
		csr.Nulls = tsr.Nulls.Clone()
	}
	return csr
}

// CopyFrom copies all avail values from other tensor into this tensor, with an
// optimized implementation if the other tensor is of the same type, and
// otherwise it goes through appropriate standard type.
// Copies Null state as well if present.
func (tsr *Float32) CopyFrom(frm Tensor) {
	if fsm, ok := frm.(*Float32); ok {
		copy(tsr.Values, fsm.Values)
		if fsm.Nulls != nil {
			if tsr.Nulls == nil {
				tsr.Nulls = bitslice.Make(tsr.Len(), 0)
			}
			copy(tsr.Nulls, fsm.Nulls)
		}
		return
	}
	sz := min(len(tsr.Values), frm.Len())
	for i := 0; i < sz; i++ {
		tsr.Values[i] = float32(frm.FloatValue1D(i))
		if frm.IsNull1D(i) {
			tsr.SetNull1D(i, true)
		}
	}
}

// CopyShapeFrom copies just the shape from given source tensor
// calling SetShape with the shape params from source (see for more docs).
func (tsr *Float32) CopyShapeFrom(frm Tensor) {
	tsr.SetShape(frm.Shapes(), frm.Strides(), frm.DimNames())
}

// CopyCellsFrom copies given range of values from other tensor into this tensor,
// using flat 1D indexes: to = starting index in this Tensor to start copying into,
// start = starting index on from Tensor to start copying from, and n = number of
// values to copy.  Uses an optimized implementation if the other tensor is
// of the same type, and otherwise it goes through appropriate standard type.
func (tsr *Float32) CopyCellsFrom(frm Tensor, to, start, n int) {
	if fsm, ok := frm.(*Float32); ok {
		for i := 0; i < n; i++ {
			tsr.Values[to+i] = fsm.Values[start+i]
			if fsm.IsNull1D(start + i) {
				tsr.SetNull1D(to+i, true)
			}
		}
		return
	}
	for i := 0; i < n; i++ {
		tsr.Values[to+i] = float32(frm.FloatValue1D(start + i))
		if frm.IsNull1D(start + i) {
			tsr.SetNull1D(to+i, true)
		}
	}
}

// SetShape sets the shape params, resizing backing storage appropriately
func (tsr *Float32) SetShape(shape, strides []int, names []string) {
	tsr.Shape.SetShape(shape, strides, names)
	nln := tsr.Len()
	if cap(tsr.Values) >= nln {
		tsr.Values = tsr.Values[0:nln]
	} else {
		nv := make([]float32, nln)
		copy(nv, tsr.Values)
		tsr.Values = nv
	}
	if tsr.Nulls != nil {
		tsr.Nulls.SetLen(nln)
	}
}

// SetNumRows sets the number of rows (outer-most dimension) in a RowMajor organized tensor.
func (tsr *Float32) SetNumRows(rows int) {
	if !tsr.IsRowMajor() {
		return
	}
	rows = max(1, rows) // must be > 0
	_, cells := tsr.RowCellSize()
	nln := rows * cells
	tsr.Shape.Shp[0] = rows
	if cap(tsr.Values) >= nln {
		tsr.Values = tsr.Values[0:nln]
	} else {
		nv := make([]float32, nln)
		copy(nv, tsr.Values)
		tsr.Values = nv
	}
	if tsr.Nulls != nil {
		tsr.Nulls.SetLen(nln)
	}
}

// SubSpace returns a new tensor with innermost subspace at given
// offset(s) in outermost dimension(s) (len(offs) < NumDims).
// Only valid for row or column major layouts.
// The new tensor points to the values of the this tensor (i.e., modifications
// will affect both), as its Values slice is a view onto the original (which
// is why only inner-most contiguous supsaces are supported).
// Use Clone() method to separate the two.
// Null value bits are NOT shared but are copied if present.
func (tsr *Float32) SubSpace(offs []int) Tensor {
	ss, _ := tsr.SubSpaceTry(offs)
	return ss
}

// SubSpaceTry returns a new tensor with innermost subspace at given
// offset(s) in outermost dimension(s) (len(offs) < NumDims).
// Try version returns an error message if the offs do not fit in tensor Shape.
// Only valid for row or column major layouts.
// The new tensor points to the values of the this tensor (i.e., modifications
// will affect both), as its Values slice is a view onto the original (which
// is why only inner-most contiguous supsaces are supported).
// Use Clone() method to separate the two.
// Null value bits are NOT shared but are copied if present.
func (tsr *Float32) SubSpaceTry(offs []int) (Tensor, error) {
	nd := tsr.NumDims()
	od := len(offs)
	if od >= nd {
		return nil, errors.New("SubSpace len(offsets) for outer dimensions was >= NumDims -- must be less")
	}
	id := nd - od
	if tsr.IsRowMajor() {
		stsr := &Float32{}
		stsr.SetShape(tsr.Shp[od:], nil, tsr.Nms[od:]) // row major def
		sti := make([]int, nd)
		copy(sti, offs)
		stoff := tsr.Offset(sti)
		sln := stsr.Len()
		stsr.Values = tsr.Values[stoff : stoff+sln]
		if tsr.Nulls != nil {
			stsr.Nulls = tsr.Nulls.SubSlice(stoff, stoff+sln)
		}
		return stsr, nil
	} else if tsr.IsColMajor() {
		stsr := &Float32{}
		stsr.SetShape(tsr.Shp[:id], nil, tsr.Nms[:id])
		stsr.Strd = ColMajorStrides(stsr.Shp)
		sti := make([]int, nd)
		for i := id; i < nd; i++ {
			sti[i] = offs[i-id]
		}
		stoff := tsr.Offset(sti)
		sln := stsr.Len()
		stsr.Values = tsr.Values[stoff : stoff+sln]
		if tsr.Nulls != nil {
			stsr.Nulls = tsr.Nulls.SubSlice(stoff, stoff+sln)
		}
		return stsr, nil
	}
	return nil, errors.New("SubSpace only valid for RowMajor or ColMajor tensors")
}

// Label satisfies the gi.Labeler interface for a summary description of the tensor
func (tsr *Float32) Label() string {
	return fmt.Sprintf("Float32: %s", tsr.Shape.String())
}

// String satisfies the fmt.Stringer interface for string of tensor data
func (tsr *Float32) String() string {
	str := tsr.Label()
	sz := len(tsr.Values)
	if sz > 1000 {
		return str
	}
	var b strings.Builder
	b.WriteString(str)
	b.WriteString("\n")
	oddRow := true
	rows, cols, _, _ := Prjn2DShape(&tsr.Shape, oddRow)
	for r := 0; r < rows; r++ {
		rc, _ := Prjn2DCoords(&tsr.Shape, oddRow, r, 0)
		b.WriteString(fmt.Sprintf("%v: ", rc))
		for c := 0; c < cols; c++ {
			vl := Prjn2DValue(tsr, oddRow, r, c)
			b.WriteString(fmt.Sprintf("%7g ", vl))
		}
		b.WriteString("\n")
	}
	return b.String()
}

// ToArrow returns the apache arrow equivalent of the tensor
func (tsr *Float32) ToArrow() *tensor.Float32 {
	bld := array.NewFloat32Builder(memory.DefaultAllocator)
	if tsr.Nulls != nil {
		bld.AppendValues(tsr.Values, tsr.Nulls.ToBools())
	} else {
		bld.AppendValues(tsr.Values, nil)
	}
	vec := bld.NewFloat32Array()
	return tensor.NewFloat32(vec.Data(), tsr.Shape64(), tsr.Strides64(), tsr.DimNames())
}

// FromArrow intializes this tensor from an arrow tensor of same type
// cpy = true means make a copy of the arrow data, otherwise it directly
// refers to its values slice -- we do not Retain() on that data so it is up
// to the go GC and / or your own memory management policies to ensure the data
// remains intact!
func (tsr *Float32) FromArrow(arw *tensor.Float32, cpy bool) {
	nms := make([]string, arw.NumDims()) // note: would be nice if it exposed DimNames()
	for i := range nms {
		nms[i] = arw.DimName(i)
	}
	tsr.SetShape64(arw.Shape(), arw.Strides(), nms)
	if cpy {
		vls := arw.Float32Values()
		tsr.Values = make([]float32, tsr.Len())
		copy(tsr.Values, vls)
	} else {
		tsr.Values = arw.Float32Values()
	}
	// note: doesn't look like the Data() exposes the nulls themselves so it is not
	// clear we can copy the null values -- nor does it seem that the tensor class
	// exposes it either!  https://github.com/apache/arrow/issues/3496
	// nln := arw.Data().NullN()
	// if nln > 0 {
	// }
}

// Dims is the gonum/mat.Matrix interface method for returning the dimensionality of the
// 2D Matrix.  Assumes Row-major ordering and logs an error if NumDims < 2.
func (tsr *Float32) Dims() (r, c int) {
	nd := tsr.NumDims()
	if nd < 2 {
		log.Println("etensor Dims gonum Matrix call made on Tensor with dims < 2")
		return 0, 0
	}
	return tsr.Dim(nd - 2), tsr.Dim(nd - 1)
}

// At is the gonum/mat.Matrix interface method for returning 2D matrix element at given
// row, column index.  Assumes Row-major ordering and logs an error if NumDims < 2.
func (tsr *Float32) At(i, j int) float64 {
	nd := tsr.NumDims()
	if nd < 2 {
		log.Println("etensor Dims gonum Matrix call made on Tensor with dims < 2")
		return 0
	} else if nd == 2 {
		return tsr.FloatValue([]int{i, j})
	} else {
		ix := make([]int, nd)
		ix[nd-2] = i
		ix[nd-1] = j
		return tsr.FloatValue(ix)
	}
}

// T is the gonum/mat.Matrix transpose method.
// It performs an implicit transpose by returning the receiver inside a Transpose.
func (tsr *Float32) T() mat.Matrix {
	return mat.Transpose{tsr}
}

// Symmetric is the gonum/mat.Matrix interface method for returning the dimensionality of a symmetric
// 2D Matrix.  Logs error if called on non-symmetric matrix.
func (tsr *Float32) Symmetric() (r int) {
	nd := tsr.NumDims()
	if nd < 2 {
		log.Println("etensor Symmetric gonum Matrix call made on Tensor with dims < 2")
		return 0
	}
	if tsr.Dim(nd-2) != tsr.Dim(nd-1) {
		log.Println("etensor Symmatrics gonum Matrix call made on Tensor that is not symmetric")
		return 0
	}
	return tsr.Dim(nd - 1)
}

// SymmetricDim is the gonum/mat.Matrix interface method for returning the dimensionality of a symmetric
// 2D Matrix.  Logs error if called on non-symmetric matrix.
func (tsr *Float32) SymmetricDim() int {
	nd := tsr.NumDims()
	if nd < 2 {
		log.Println("etensor Symmetric gonum Matrix call made on Tensor with dims < 2")
		return 0
	}
	if tsr.Dim(nd-2) != tsr.Dim(nd-1) {
		log.Println("etensor Symmetric gonum Matrix call made on Tensor that is not symmetric")
		return 0
	}
	return tsr.Dim(nd - 1)
}

// SetMetaData sets a key=value meta data (stored as a map[string]string).
// For TensorGrid display: top-zero=+/-, odd-row=+/-, image=+/-,
// min, max set fixed min / max values, background=color
func (tsr *Float32) SetMetaData(key, val string) {
	if tsr.Meta == nil {
		tsr.Meta = make(map[string]string)
	}
	tsr.Meta[key] = val
}

// MetaData retrieves value of given key, bool = false if not set
func (tsr *Float32) MetaData(key string) (string, bool) {
	if tsr.Meta == nil {
		return "", false
	}
	val, ok := tsr.Meta[key]
	return val, ok
}

// MetaDataMap returns the underlying map used for meta data
func (tsr *Float32) MetaDataMap() map[string]string {
	return tsr.Meta
}

// CopyMetaData copies meta data from given source tensor
func (tsr *Float32) CopyMetaData(frm Tensor) {
	fmap := frm.MetaDataMap()
	if len(fmap) == 0 {
		return
	}
	if tsr.Meta == nil {
		tsr.Meta = make(map[string]string)
	}
	for k, v := range fmap {
		tsr.Meta[k] = v
	}
}

// Int16 is an n-dim array of int16s.
type Int16 struct {
	Shape
	Values []int16
	Nulls  bitslice.Slice
	Meta   map[string]string
}

// NewInt16 returns a new n-dimensional array of int16s.
// If strides is nil, row-major strides will be inferred.
// If names is nil, a slice of empty strings will be created.
// Nulls are initialized to nil.
func NewInt16(shape, strides []int, names []string) *Int16 {
	tsr := &Int16{}
	tsr.SetShape(shape, strides, names)
	tsr.Values = make([]int16, tsr.Len())
	return tsr
}

// NewInt16Shape returns a new n-dimensional array of int16s.
// Using shape structure instead of separate slices, and optionally
// existing values if vals != nil (must be of proper length) -- we
// directly set our internal Values = vals, thereby sharing the same
// underlying data. Nulls are initialized to nil.
func NewInt16Shape(shape *Shape, vals []int16) *Int16 {
	tsr := &Int16{}
	tsr.CopyShape(shape)
	if vals != nil {
		if len(vals) != tsr.Len() {
			log.Printf("etensor.NewInt16Shape: length of provided vals: %d not proper length: %d", len(vals), tsr.Len())
			tsr.Values = make([]int16, tsr.Len())
		} else {
			tsr.Values = vals
		}
	} else {
		tsr.Values = make([]int16, tsr.Len())
	}
	return tsr
}

func (tsr *Int16) ShapeObj() *Shape       { return &tsr.Shape }
func (tsr *Int16) DataType() Type         { return INT16 }
func (tsr *Int16) Value(i []int) int16    { j := tsr.Offset(i); return tsr.Values[j] }
func (tsr *Int16) Value1D(i int) int16    { return tsr.Values[i] }
func (tsr *Int16) Set(i []int, val int16) { j := tsr.Offset(i); tsr.Values[j] = val }
func (tsr *Int16) Set1D(i int, val int16) { tsr.Values[i] = val }
func (tsr *Int16) AddScalar(i []int, val int16) int16 {
	j := tsr.Offset(i)
	tsr.Values[j] += val
	return tsr.Values[j]
}
func (tsr *Int16) MulScalar(i []int, val int16) int16 {
	j := tsr.Offset(i)
	tsr.Values[j] *= val
	return tsr.Values[j]
}

// IsNull returns true if the given index has been flagged as a Null
// (undefined, not present) value
func (tsr *Int16) IsNull(i []int) bool {
	if tsr.Nulls == nil {
		return false
	}
	j := tsr.Offset(i)
	return tsr.Nulls.Index(j)
}

// IsNull1D returns true if the given 1-dimensional index has been flagged as a Null
// (undefined, not present) value
func (tsr *Int16) IsNull1D(i int) bool {
	if tsr.Nulls == nil {
		return false
	}
	return tsr.Nulls.Index(i)
}

// SetNull sets whether given index has a null value or not.
// All values are assumed valid (non-Null) until marked otherwise, and calling
// this method creates a Null bitslice map if one has not already been set yet.
func (tsr *Int16) SetNull(i []int, nul bool) {
	if tsr.Nulls == nil {
		tsr.Nulls = bitslice.Make(tsr.Len(), 0)
	}
	j := tsr.Offset(i)
	tsr.Nulls.Set(j, nul)
}

// SetNull1D sets whether given 1-dimensional index has a null value or not.
// All values are assumed valid (non-Null) until marked otherwise, and calling
// this method creates a Null bitslice map if one has not already been set yet.
func (tsr *Int16) SetNull1D(i int, nul bool) {
	if tsr.Nulls == nil {
		tsr.Nulls = bitslice.Make(tsr.Len(), 0)
	}
	tsr.Nulls.Set(i, nul)
}

func (tsr *Int16) FloatValue(i []int) float64      { j := tsr.Offset(i); return float64(tsr.Values[j]) }
func (tsr *Int16) SetFloat(i []int, val float64) { j := tsr.Offset(i); tsr.Values[j] = int16(val) }

func (tsr *Int16) StringValue(i []int) string { j := tsr.Offset(i); return laser.ToString(tsr.Values[j]) }
func (tsr *Int16) SetString(i []int, val string) {
	if fv, err := strconv.ParseFloat(val, 64); err == nil {
		j := tsr.Offset(i)
		tsr.Values[j] = int16(fv)
	}
}

func (tsr *Int16) FloatValue1D(off int) float64      { return float64(tsr.Values[off]) }
func (tsr *Int16) SetFloat1D(off int, val float64) { tsr.Values[off] = int16(val) }

func (tsr *Int16) FloatValueRowCell(row, cell int) float64 {
	_, sz := tsr.RowCellSize()
	return float64(tsr.Values[row*sz+cell])
}
func (tsr *Int16) SetFloatRowCell(row, cell int, val float64) {
	_, sz := tsr.RowCellSize()
	tsr.Values[row*sz+cell] = int16(val)
}

// Floats sets []float64 slice of all elements in the tensor
// (length is ensured to be sufficient).
// This can be used for all of the gonum/floats methods
// for basic math, gonum/stats, etc.
func (tsr *Int16) Floats(flt *[]float64) {
	SetFloat64SliceLen(flt, len(tsr.Values))
	for j, vl := range tsr.Values {
		(*flt)[j] = float64(vl)
	}
}

// SetFloats sets tensor values from a []float64 slice (copies values).
func (tsr *Int16) SetFloats(vals []float64) {
	sz := min(len(tsr.Values), len(vals))
	for j := 0; j < sz; j++ {
		tsr.Values[j] = int16(vals[j])
	}
}

func (tsr *Int16) StringValue1D(off int) string { return laser.ToString(tsr.Values[off]) }
func (tsr *Int16) SetString1D(off int, val string) {
	if fv, err := strconv.ParseFloat(val, 64); err == nil {
		tsr.Values[off] = int16(fv)
	}
}

func (tsr *Int16) StringValueRowCell(row, cell int) string {
	_, sz := tsr.RowCellSize()
	return laser.ToString(tsr.Values[row*sz+cell])
}
func (tsr *Int16) SetStringRowCell(row, cell int, val string) {
	if fv, err := strconv.ParseFloat(val, 64); err == nil {
		_, sz := tsr.RowCellSize()
		tsr.Values[row*sz+cell] = int16(fv)
	}
}

// Range returns the min, max (and associated indexes, -1 = no values) for the tensor.
// This is needed for display and is thus in the core api in optimized form
// Other math operations can be done using gonum/floats package.
func (tsr *Int16) Range() (min, max float64, minIndex, maxIndex int) {
	minIndex = -1
	maxIndex = -1
	for j, vl := range tsr.Values {
		fv := float64(vl)
		if math.IsNaN(fv) {
			continue
		}
		if fv < min || minIndex < 0 {
			min = fv
			minIndex = j
		}
		if fv > max || maxIndex < 0 {
			max = fv
			maxIndex = j
		}
	}
	return
}

// Agg applies given aggregation function to each element in the tensor
// (automatically skips IsNull and NaN elements), using float64 conversions of the values.
// init is the initial value for the agg variable. returns final aggregate value
func (tsr *Int16) Agg(ini float64, fun AggFunc) float64 {
	ag := ini
	for j, vl := range tsr.Values {
		val := float64(vl)
		if !tsr.IsNull1D(j) && !math.IsNaN(val) {
			ag = fun(j, val, ag)
		}
	}
	return ag
}

// Eval applies given function to each element in the tensor (automatically
// skips IsNull and NaN elements), using float64 conversions of the values.
// Puts the results into given float64 slice, which is ensured to be of the proper length.
func (tsr *Int16) Eval(res *[]float64, fun EvalFunc) {
	ln := tsr.Len()
	if len(*res) != ln {
		*res = make([]float64, ln)
	}
	for j, vl := range tsr.Values {
		val := float64(vl)
		if !tsr.IsNull1D(j) && !math.IsNaN(val) {
			(*res)[j] = fun(j, val)
		}
	}
}

// SetFunc applies given function to each element in the tensor (automatically
// skips IsNull and NaN elements), using float64 conversions of the values.
// Writes the results back into the same tensor elements.
func (tsr *Int16) SetFunc(fun EvalFunc) {
	for j, vl := range tsr.Values {
		val := float64(vl)
		if !tsr.IsNull1D(j) && !math.IsNaN(val) {
			tsr.Values[j] = int16(fun(j, val))
		}
	}
}

// SetZeros is simple convenience function initialize all values to 0
func (tsr *Int16) SetZeros() {
	for j := range tsr.Values {
		tsr.Values[j] = 0
	}
}

// Clone clones this tensor, creating a duplicate copy of itself with its
// own separate memory representation of all the values, and returns
// that as a Tensor (which can be converted into the known type as needed).
func (tsr *Int16) Clone() Tensor {
	csr := NewInt16Shape(&tsr.Shape, nil)
	copy(csr.Values, tsr.Values)
	if tsr.Nulls != nil {
		csr.Nulls = tsr.Nulls.Clone()
	}
	return csr
}

// CopyFrom copies all avail values from other tensor into this tensor, with an
// optimized implementation if the other tensor is of the same type, and
// otherwise it goes through appropriate standard type.
// Copies Null state as well if present.
func (tsr *Int16) CopyFrom(frm Tensor) {
	if fsm, ok := frm.(*Int16); ok {
		copy(tsr.Values, fsm.Values)
		if fsm.Nulls != nil {
			if tsr.Nulls == nil {
				tsr.Nulls = bitslice.Make(tsr.Len(), 0)
			}
			copy(tsr.Nulls, fsm.Nulls)
		}
		return
	}
	sz := min(len(tsr.Values), frm.Len())
	for i := 0; i < sz; i++ {
		tsr.Values[i] = int16(frm.FloatValue1D(i))
		if frm.IsNull1D(i) {
			tsr.SetNull1D(i, true)
		}
	}
}

// CopyShapeFrom copies just the shape from given source tensor
// calling SetShape with the shape params from source (see for more docs).
func (tsr *Int16) CopyShapeFrom(frm Tensor) {
	tsr.SetShape(frm.Shapes(), frm.Strides(), frm.DimNames())
}

// CopyCellsFrom copies given range of values from other tensor into this tensor,
// using flat 1D indexes: to = starting index in this Tensor to start copying into,
// start = starting index on from Tensor to start copying from, and n = number of
// values to copy.  Uses an optimized implementation if the other tensor is
// of the same type, and otherwise it goes through appropriate standard type.
func (tsr *Int16) CopyCellsFrom(frm Tensor, to, start, n int) {
	if fsm, ok := frm.(*Int16); ok {
		for i := 0; i < n; i++ {
			tsr.Values[to+i] = fsm.Values[start+i]
			if fsm.IsNull1D(start + i) {
				tsr.SetNull1D(to+i, true)
			}
		}
		return
	}
	for i := 0; i < n; i++ {
		tsr.Values[to+i] = int16(frm.FloatValue1D(start + i))
		if frm.IsNull1D(start + i) {
			tsr.SetNull1D(to+i, true)
		}
	}
}

// SetShape sets the shape params, resizing backing storage appropriately
func (tsr *Int16) SetShape(shape, strides []int, names []string) {
	tsr.Shape.SetShape(shape, strides, names)
	nln := tsr.Len()
	if cap(tsr.Values) >= nln {
		tsr.Values = tsr.Values[0:nln]
	} else {
		nv := make([]int16, nln)
		copy(nv, tsr.Values)
		tsr.Values = nv
	}
	if tsr.Nulls != nil {
		tsr.Nulls.SetLen(nln)
	}
}

// SetNumRows sets the number of rows (outer-most dimension) in a RowMajor organized tensor.
func (tsr *Int16) SetNumRows(rows int) {
	if !tsr.IsRowMajor() {
		return
	}
	rows = max(1, rows) // must be > 0
	_, cells := tsr.RowCellSize()
	nln := rows * cells
	tsr.Shape.Shp[0] = rows
	if cap(tsr.Values) >= nln {
		tsr.Values = tsr.Values[0:nln]
	} else {
		nv := make([]int16, nln)
		copy(nv, tsr.Values)
		tsr.Values = nv
	}
	if tsr.Nulls != nil {
		tsr.Nulls.SetLen(nln)
	}
}

// SubSpace returns a new tensor with innermost subspace at given
// offset(s) in outermost dimension(s) (len(offs) < NumDims).
// Only valid for row or column major layouts.
// The new tensor points to the values of the this tensor (i.e., modifications
// will affect both), as its Values slice is a view onto the original (which
// is why only inner-most contiguous supsaces are supported).
// Use Clone() method to separate the two.
// Null value bits are NOT shared but are copied if present.
func (tsr *Int16) SubSpace(offs []int) Tensor {
	ss, _ := tsr.SubSpaceTry(offs)
	return ss
}

// SubSpaceTry returns a new tensor with innermost subspace at given
// offset(s) in outermost dimension(s) (len(offs) < NumDims).
// Try version returns an error message if the offs do not fit in tensor Shape.
// Only valid for row or column major layouts.
// The new tensor points to the values of the this tensor (i.e., modifications
// will affect both), as its Values slice is a view onto the original (which
// is why only inner-most contiguous supsaces are supported).
// Use Clone() method to separate the two.
// Null value bits are NOT shared but are copied if present.
func (tsr *Int16) SubSpaceTry(offs []int) (Tensor, error) {
	nd := tsr.NumDims()
	od := len(offs)
	if od >= nd {
		return nil, errors.New("SubSpace len(offsets) for outer dimensions was >= NumDims -- must be less")
	}
	id := nd - od
	if tsr.IsRowMajor() {
		stsr := &Int16{}
		stsr.SetShape(tsr.Shp[od:], nil, tsr.Nms[od:]) // row major def
		sti := make([]int, nd)
		copy(sti, offs)
		stoff := tsr.Offset(sti)
		sln := stsr.Len()
		stsr.Values = tsr.Values[stoff : stoff+sln]
		if tsr.Nulls != nil {
			stsr.Nulls = tsr.Nulls.SubSlice(stoff, stoff+sln)
		}
		return stsr, nil
	} else if tsr.IsColMajor() {
		stsr := &Int16{}
		stsr.SetShape(tsr.Shp[:id], nil, tsr.Nms[:id])
		stsr.Strd = ColMajorStrides(stsr.Shp)
		sti := make([]int, nd)
		for i := id; i < nd; i++ {
			sti[i] = offs[i-id]
		}
		stoff := tsr.Offset(sti)
		sln := stsr.Len()
		stsr.Values = tsr.Values[stoff : stoff+sln]
		if tsr.Nulls != nil {
			stsr.Nulls = tsr.Nulls.SubSlice(stoff, stoff+sln)
		}
		return stsr, nil
	}
	return nil, errors.New("SubSpace only valid for RowMajor or ColMajor tensors")
}

// Label satisfies the gi.Labeler interface for a summary description of the tensor
func (tsr *Int16) Label() string {
	return fmt.Sprintf("Int16: %s", tsr.Shape.String())
}

// String satisfies the fmt.Stringer interface for string of tensor data
func (tsr *Int16) String() string {
	str := tsr.Label()
	sz := len(tsr.Values)
	if sz > 1000 {
		return str
	}
	var b strings.Builder
	b.WriteString(str)
	b.WriteString("\n")
	oddRow := true
	rows, cols, _, _ := Prjn2DShape(&tsr.Shape, oddRow)
	for r := 0; r < rows; r++ {
		rc, _ := Prjn2DCoords(&tsr.Shape, oddRow, r, 0)
		b.WriteString(fmt.Sprintf("%v: ", rc))
		for c := 0; c < cols; c++ {
			vl := Prjn2DValue(tsr, oddRow, r, c)
			b.WriteString(fmt.Sprintf("%7g ", vl))
		}
		b.WriteString("\n")
	}
	return b.String()
}

// ToArrow returns the apache arrow equivalent of the tensor
func (tsr *Int16) ToArrow() *tensor.Int16 {
	bld := array.NewInt16Builder(memory.DefaultAllocator)
	if tsr.Nulls != nil {
		bld.AppendValues(tsr.Values, tsr.Nulls.ToBools())
	} else {
		bld.AppendValues(tsr.Values, nil)
	}
	vec := bld.NewInt16Array()
	return tensor.NewInt16(vec.Data(), tsr.Shape64(), tsr.Strides64(), tsr.DimNames())
}

// FromArrow intializes this tensor from an arrow tensor of same type
// cpy = true means make a copy of the arrow data, otherwise it directly
// refers to its values slice -- we do not Retain() on that data so it is up
// to the go GC and / or your own memory management policies to ensure the data
// remains intact!
func (tsr *Int16) FromArrow(arw *tensor.Int16, cpy bool) {
	nms := make([]string, arw.NumDims()) // note: would be nice if it exposed DimNames()
	for i := range nms {
		nms[i] = arw.DimName(i)
	}
	tsr.SetShape64(arw.Shape(), arw.Strides(), nms)
	if cpy {
		vls := arw.Int16Values()
		tsr.Values = make([]int16, tsr.Len())
		copy(tsr.Values, vls)
	} else {
		tsr.Values = arw.Int16Values()
	}
	// note: doesn't look like the Data() exposes the nulls themselves so it is not
	// clear we can copy the null values -- nor does it seem that the tensor class
	// exposes it either!  https://github.com/apache/arrow/issues/3496
	// nln := arw.Data().NullN()
	// if nln > 0 {
	// }
}

// Dims is the gonum/mat.Matrix interface method for returning the dimensionality of the
// 2D Matrix.  Assumes Row-major ordering and logs an error if NumDims < 2.
func (tsr *Int16) Dims() (r, c int) {
	nd := tsr.NumDims()
	if nd < 2 {
		log.Println("etensor Dims gonum Matrix call made on Tensor with dims < 2")
		return 0, 0
	}
	return tsr.Dim(nd - 2), tsr.Dim(nd - 1)
}

// At is the gonum/mat.Matrix interface method for returning 2D matrix element at given
// row, column index.  Assumes Row-major ordering and logs an error if NumDims < 2.
func (tsr *Int16) At(i, j int) float64 {
	nd := tsr.NumDims()
	if nd < 2 {
		log.Println("etensor Dims gonum Matrix call made on Tensor with dims < 2")
		return 0
	} else if nd == 2 {
		return tsr.FloatValue([]int{i, j})
	} else {
		ix := make([]int, nd)
		ix[nd-2] = i
		ix[nd-1] = j
		return tsr.FloatValue(ix)
	}
}

// T is the gonum/mat.Matrix transpose method.
// It performs an implicit transpose by returning the receiver inside a Transpose.
func (tsr *Int16) T() mat.Matrix {
	return mat.Transpose{tsr}
}

// Symmetric is the gonum/mat.Matrix interface method for returning the dimensionality of a symmetric
// 2D Matrix.  Logs error if called on non-symmetric matrix.
func (tsr *Int16) Symmetric() (r int) {
	nd := tsr.NumDims()
	if nd < 2 {
		log.Println("etensor Symmetric gonum Matrix call made on Tensor with dims < 2")
		return 0
	}
	if tsr.Dim(nd-2) != tsr.Dim(nd-1) {
		log.Println("etensor Symmatrics gonum Matrix call made on Tensor that is not symmetric")
		return 0
	}
	return tsr.Dim(nd - 1)
}

// SymmetricDim is the gonum/mat.Matrix interface method for returning the dimensionality of a symmetric
// 2D Matrix.  Logs error if called on non-symmetric matrix.
func (tsr *Int16) SymmetricDim() int {
	nd := tsr.NumDims()
	if nd < 2 {
		log.Println("etensor Symmetric gonum Matrix call made on Tensor with dims < 2")
		return 0
	}
	if tsr.Dim(nd-2) != tsr.Dim(nd-1) {
		log.Println("etensor Symmetric gonum Matrix call made on Tensor that is not symmetric")
		return 0
	}
	return tsr.Dim(nd - 1)
}

// SetMetaData sets a key=value meta data (stored as a map[string]string).
// For TensorGrid display: top-zero=+/-, odd-row=+/-, image=+/-,
// min, max set fixed min / max values, background=color
func (tsr *Int16) SetMetaData(key, val string) {
	if tsr.Meta == nil {
		tsr.Meta = make(map[string]string)
	}
	tsr.Meta[key] = val
}

// MetaData retrieves value of given key, bool = false if not set
func (tsr *Int16) MetaData(key string) (string, bool) {
	if tsr.Meta == nil {
		return "", false
	}
	val, ok := tsr.Meta[key]
	return val, ok
}

// MetaDataMap returns the underlying map used for meta data
func (tsr *Int16) MetaDataMap() map[string]string {
	return tsr.Meta
}

// CopyMetaData copies meta data from given source tensor
func (tsr *Int16) CopyMetaData(frm Tensor) {
	fmap := frm.MetaDataMap()
	if len(fmap) == 0 {
		return
	}
	if tsr.Meta == nil {
		tsr.Meta = make(map[string]string)
	}
	for k, v := range fmap {
		tsr.Meta[k] = v
	}
}

// Uint16 is an n-dim array of uint16s.
type Uint16 struct {
	Shape
	Values []uint16
	Nulls  bitslice.Slice
	Meta   map[string]string
}

// NewUint16 returns a new n-dimensional array of uint16s.
// If strides is nil, row-major strides will be inferred.
// If names is nil, a slice of empty strings will be created.
// Nulls are initialized to nil.
func NewUint16(shape, strides []int, names []string) *Uint16 {
	tsr := &Uint16{}
	tsr.SetShape(shape, strides, names)
	tsr.Values = make([]uint16, tsr.Len())
	return tsr
}

// NewUint16Shape returns a new n-dimensional array of uint16s.
// Using shape structure instead of separate slices, and optionally
// existing values if vals != nil (must be of proper length) -- we
// directly set our internal Values = vals, thereby sharing the same
// underlying data. Nulls are initialized to nil.
func NewUint16Shape(shape *Shape, vals []uint16) *Uint16 {
	tsr := &Uint16{}
	tsr.CopyShape(shape)
	if vals != nil {
		if len(vals) != tsr.Len() {
			log.Printf("etensor.NewUint16Shape: length of provided vals: %d not proper length: %d", len(vals), tsr.Len())
			tsr.Values = make([]uint16, tsr.Len())
		} else {
			tsr.Values = vals
		}
	} else {
		tsr.Values = make([]uint16, tsr.Len())
	}
	return tsr
}

func (tsr *Uint16) ShapeObj() *Shape        { return &tsr.Shape }
func (tsr *Uint16) DataType() Type          { return UINT16 }
func (tsr *Uint16) Value(i []int) uint16    { j := tsr.Offset(i); return tsr.Values[j] }
func (tsr *Uint16) Value1D(i int) uint16    { return tsr.Values[i] }
func (tsr *Uint16) Set(i []int, val uint16) { j := tsr.Offset(i); tsr.Values[j] = val }
func (tsr *Uint16) Set1D(i int, val uint16) { tsr.Values[i] = val }
func (tsr *Uint16) AddScalar(i []int, val uint16) uint16 {
	j := tsr.Offset(i)
	tsr.Values[j] += val
	return tsr.Values[j]
}
func (tsr *Uint16) MulScalar(i []int, val uint16) uint16 {
	j := tsr.Offset(i)
	tsr.Values[j] *= val
	return tsr.Values[j]
}

// IsNull returns true if the given index has been flagged as a Null
// (undefined, not present) value
func (tsr *Uint16) IsNull(i []int) bool {
	if tsr.Nulls == nil {
		return false
	}
	j := tsr.Offset(i)
	return tsr.Nulls.Index(j)
}

// IsNull1D returns true if the given 1-dimensional index has been flagged as a Null
// (undefined, not present) value
func (tsr *Uint16) IsNull1D(i int) bool {
	if tsr.Nulls == nil {
		return false
	}
	return tsr.Nulls.Index(i)
}

// SetNull sets whether given index has a null value or not.
// All values are assumed valid (non-Null) until marked otherwise, and calling
// this method creates a Null bitslice map if one has not already been set yet.
func (tsr *Uint16) SetNull(i []int, nul bool) {
	if tsr.Nulls == nil {
		tsr.Nulls = bitslice.Make(tsr.Len(), 0)
	}
	j := tsr.Offset(i)
	tsr.Nulls.Set(j, nul)
}

// SetNull1D sets whether given 1-dimensional index has a null value or not.
// All values are assumed valid (non-Null) until marked otherwise, and calling
// this method creates a Null bitslice map if one has not already been set yet.
func (tsr *Uint16) SetNull1D(i int, nul bool) {
	if tsr.Nulls == nil {
		tsr.Nulls = bitslice.Make(tsr.Len(), 0)
	}
	tsr.Nulls.Set(i, nul)
}

func (tsr *Uint16) FloatValue(i []int) float64      { j := tsr.Offset(i); return float64(tsr.Values[j]) }
func (tsr *Uint16) SetFloat(i []int, val float64) { j := tsr.Offset(i); tsr.Values[j] = uint16(val) }

func (tsr *Uint16) StringValue(i []int) string {
	j := tsr.Offset(i)
	return laser.ToString(tsr.Values[j])
}
func (tsr *Uint16) SetString(i []int, val string) {
	if fv, err := strconv.ParseFloat(val, 64); err == nil {
		j := tsr.Offset(i)
		tsr.Values[j] = uint16(fv)
	}
}

func (tsr *Uint16) FloatValue1D(off int) float64      { return float64(tsr.Values[off]) }
func (tsr *Uint16) SetFloat1D(off int, val float64) { tsr.Values[off] = uint16(val) }

func (tsr *Uint16) FloatValueRowCell(row, cell int) float64 {
	_, sz := tsr.RowCellSize()
	return float64(tsr.Values[row*sz+cell])
}
func (tsr *Uint16) SetFloatRowCell(row, cell int, val float64) {
	_, sz := tsr.RowCellSize()
	tsr.Values[row*sz+cell] = uint16(val)
}

// Floats sets []float64 slice of all elements in the tensor
// (length is ensured to be sufficient).
// This can be used for all of the gonum/floats methods
// for basic math, gonum/stats, etc.
func (tsr *Uint16) Floats(flt *[]float64) {
	SetFloat64SliceLen(flt, len(tsr.Values))
	for j, vl := range tsr.Values {
		(*flt)[j] = float64(vl)
	}
}

// SetFloats sets tensor values from a []float64 slice (copies values).
func (tsr *Uint16) SetFloats(vals []float64) {
	sz := min(len(tsr.Values), len(vals))
	for j := 0; j < sz; j++ {
		tsr.Values[j] = uint16(vals[j])
	}
}

func (tsr *Uint16) StringValue1D(off int) string { return laser.ToString(tsr.Values[off]) }
func (tsr *Uint16) SetString1D(off int, val string) {
	if fv, err := strconv.ParseFloat(val, 64); err == nil {
		tsr.Values[off] = uint16(fv)
	}
}

func (tsr *Uint16) StringValueRowCell(row, cell int) string {
	_, sz := tsr.RowCellSize()
	return laser.ToString(tsr.Values[row*sz+cell])
}
func (tsr *Uint16) SetStringRowCell(row, cell int, val string) {
	if fv, err := strconv.ParseFloat(val, 64); err == nil {
		_, sz := tsr.RowCellSize()
		tsr.Values[row*sz+cell] = uint16(fv)
	}
}

// Range returns the min, max (and associated indexes, -1 = no values) for the tensor.
// This is needed for display and is thus in the core api in optimized form
// Other math operations can be done using gonum/floats package.
func (tsr *Uint16) Range() (min, max float64, minIndex, maxIndex int) {
	minIndex = -1
	maxIndex = -1
	for j, vl := range tsr.Values {
		fv := float64(vl)
		if math.IsNaN(fv) {
			continue
		}
		if fv < min || minIndex < 0 {
			min = fv
			minIndex = j
		}
		if fv > max || maxIndex < 0 {
			max = fv
			maxIndex = j
		}
	}
	return
}

// Agg applies given aggregation function to each element in the tensor
// (automatically skips IsNull and NaN elements), using float64 conversions of the values.
// init is the initial value for the agg variable. returns final aggregate value
func (tsr *Uint16) Agg(ini float64, fun AggFunc) float64 {
	ag := ini
	for j, vl := range tsr.Values {
		val := float64(vl)
		if !tsr.IsNull1D(j) && !math.IsNaN(val) {
			ag = fun(j, val, ag)
		}
	}
	return ag
}

// Eval applies given function to each element in the tensor (automatically
// skips IsNull and NaN elements), using float64 conversions of the values.
// Puts the results into given float64 slice, which is ensured to be of the proper length.
func (tsr *Uint16) Eval(res *[]float64, fun EvalFunc) {
	ln := tsr.Len()
	if len(*res) != ln {
		*res = make([]float64, ln)
	}
	for j, vl := range tsr.Values {
		val := float64(vl)
		if !tsr.IsNull1D(j) && !math.IsNaN(val) {
			(*res)[j] = fun(j, val)
		}
	}
}

// SetFunc applies given function to each element in the tensor (automatically
// skips IsNull and NaN elements), using float64 conversions of the values.
// Writes the results back into the same tensor elements.
func (tsr *Uint16) SetFunc(fun EvalFunc) {
	for j, vl := range tsr.Values {
		val := float64(vl)
		if !tsr.IsNull1D(j) && !math.IsNaN(val) {
			tsr.Values[j] = uint16(fun(j, val))
		}
	}
}

// SetZeros is simple convenience function initialize all values to 0
func (tsr *Uint16) SetZeros() {
	for j := range tsr.Values {
		tsr.Values[j] = 0
	}
}

// Clone clones this tensor, creating a duplicate copy of itself with its
// own separate memory representation of all the values, and returns
// that as a Tensor (which can be converted into the known type as needed).
func (tsr *Uint16) Clone() Tensor {
	csr := NewUint16Shape(&tsr.Shape, nil)
	copy(csr.Values, tsr.Values)
	if tsr.Nulls != nil {
		csr.Nulls = tsr.Nulls.Clone()
	}
	return csr
}

// CopyFrom copies all avail values from other tensor into this tensor, with an
// optimized implementation if the other tensor is of the same type, and
// otherwise it goes through appropriate standard type.
// Copies Null state as well if present.
func (tsr *Uint16) CopyFrom(frm Tensor) {
	if fsm, ok := frm.(*Uint16); ok {
		copy(tsr.Values, fsm.Values)
		if fsm.Nulls != nil {
			if tsr.Nulls == nil {
				tsr.Nulls = bitslice.Make(tsr.Len(), 0)
			}
			copy(tsr.Nulls, fsm.Nulls)
		}
		return
	}
	sz := min(len(tsr.Values), frm.Len())
	for i := 0; i < sz; i++ {
		tsr.Values[i] = uint16(frm.FloatValue1D(i))
		if frm.IsNull1D(i) {
			tsr.SetNull1D(i, true)
		}
	}
}

// CopyShapeFrom copies just the shape from given source tensor
// calling SetShape with the shape params from source (see for more docs).
func (tsr *Uint16) CopyShapeFrom(frm Tensor) {
	tsr.SetShape(frm.Shapes(), frm.Strides(), frm.DimNames())
}

// CopyCellsFrom copies given range of values from other tensor into this tensor,
// using flat 1D indexes: to = starting index in this Tensor to start copying into,
// start = starting index on from Tensor to start copying from, and n = number of
// values to copy.  Uses an optimized implementation if the other tensor is
// of the same type, and otherwise it goes through appropriate standard type.
func (tsr *Uint16) CopyCellsFrom(frm Tensor, to, start, n int) {
	if fsm, ok := frm.(*Uint16); ok {
		for i := 0; i < n; i++ {
			tsr.Values[to+i] = fsm.Values[start+i]
			if fsm.IsNull1D(start + i) {
				tsr.SetNull1D(to+i, true)
			}
		}
		return
	}
	for i := 0; i < n; i++ {
		tsr.Values[to+i] = uint16(frm.FloatValue1D(start + i))
		if frm.IsNull1D(start + i) {
			tsr.SetNull1D(to+i, true)
		}
	}
}

// SetShape sets the shape params, resizing backing storage appropriately
func (tsr *Uint16) SetShape(shape, strides []int, names []string) {
	tsr.Shape.SetShape(shape, strides, names)
	nln := tsr.Len()
	if cap(tsr.Values) >= nln {
		tsr.Values = tsr.Values[0:nln]
	} else {
		nv := make([]uint16, nln)
		copy(nv, tsr.Values)
		tsr.Values = nv
	}
	if tsr.Nulls != nil {
		tsr.Nulls.SetLen(nln)
	}
}

// SetNumRows sets the number of rows (outer-most dimension) in a RowMajor organized tensor.
func (tsr *Uint16) SetNumRows(rows int) {
	if !tsr.IsRowMajor() {
		return
	}
	rows = max(1, rows) // must be > 0
	_, cells := tsr.RowCellSize()
	nln := rows * cells
	tsr.Shape.Shp[0] = rows
	if cap(tsr.Values) >= nln {
		tsr.Values = tsr.Values[0:nln]
	} else {
		nv := make([]uint16, nln)
		copy(nv, tsr.Values)
		tsr.Values = nv
	}
	if tsr.Nulls != nil {
		tsr.Nulls.SetLen(nln)
	}
}

// SubSpace returns a new tensor with innermost subspace at given
// offset(s) in outermost dimension(s) (len(offs) < NumDims).
// Only valid for row or column major layouts.
// The new tensor points to the values of the this tensor (i.e., modifications
// will affect both), as its Values slice is a view onto the original (which
// is why only inner-most contiguous supsaces are supported).
// Use Clone() method to separate the two.
// Null value bits are NOT shared but are copied if present.
func (tsr *Uint16) SubSpace(offs []int) Tensor {
	ss, _ := tsr.SubSpaceTry(offs)
	return ss
}

// SubSpaceTry returns a new tensor with innermost subspace at given
// offset(s) in outermost dimension(s) (len(offs) < NumDims).
// Try version returns an error message if the offs do not fit in tensor Shape.
// Only valid for row or column major layouts.
// The new tensor points to the values of the this tensor (i.e., modifications
// will affect both), as its Values slice is a view onto the original (which
// is why only inner-most contiguous supsaces are supported).
// Use Clone() method to separate the two.
// Null value bits are NOT shared but are copied if present.
func (tsr *Uint16) SubSpaceTry(offs []int) (Tensor, error) {
	nd := tsr.NumDims()
	od := len(offs)
	if od >= nd {
		return nil, errors.New("SubSpace len(offsets) for outer dimensions was >= NumDims -- must be less")
	}
	id := nd - od
	if tsr.IsRowMajor() {
		stsr := &Uint16{}
		stsr.SetShape(tsr.Shp[od:], nil, tsr.Nms[od:]) // row major def
		sti := make([]int, nd)
		copy(sti, offs)
		stoff := tsr.Offset(sti)
		sln := stsr.Len()
		stsr.Values = tsr.Values[stoff : stoff+sln]
		if tsr.Nulls != nil {
			stsr.Nulls = tsr.Nulls.SubSlice(stoff, stoff+sln)
		}
		return stsr, nil
	} else if tsr.IsColMajor() {
		stsr := &Uint16{}
		stsr.SetShape(tsr.Shp[:id], nil, tsr.Nms[:id])
		stsr.Strd = ColMajorStrides(stsr.Shp)
		sti := make([]int, nd)
		for i := id; i < nd; i++ {
			sti[i] = offs[i-id]
		}
		stoff := tsr.Offset(sti)
		sln := stsr.Len()
		stsr.Values = tsr.Values[stoff : stoff+sln]
		if tsr.Nulls != nil {
			stsr.Nulls = tsr.Nulls.SubSlice(stoff, stoff+sln)
		}
		return stsr, nil
	}
	return nil, errors.New("SubSpace only valid for RowMajor or ColMajor tensors")
}

// Label satisfies the gi.Labeler interface for a summary description of the tensor
func (tsr *Uint16) Label() string {
	return fmt.Sprintf("Uint16: %s", tsr.Shape.String())
}

// String satisfies the fmt.Stringer interface for string of tensor data
func (tsr *Uint16) String() string {
	str := tsr.Label()
	sz := len(tsr.Values)
	if sz > 1000 {
		return str
	}
	var b strings.Builder
	b.WriteString(str)
	b.WriteString("\n")
	oddRow := true
	rows, cols, _, _ := Prjn2DShape(&tsr.Shape, oddRow)
	for r := 0; r < rows; r++ {
		rc, _ := Prjn2DCoords(&tsr.Shape, oddRow, r, 0)
		b.WriteString(fmt.Sprintf("%v: ", rc))
		for c := 0; c < cols; c++ {
			vl := Prjn2DValue(tsr, oddRow, r, c)
			b.WriteString(fmt.Sprintf("%7g ", vl))
		}
		b.WriteString("\n")
	}
	return b.String()
}

// ToArrow returns the apache arrow equivalent of the tensor
func (tsr *Uint16) ToArrow() *tensor.Uint16 {
	bld := array.NewUint16Builder(memory.DefaultAllocator)
	if tsr.Nulls != nil {
		bld.AppendValues(tsr.Values, tsr.Nulls.ToBools())
	} else {
		bld.AppendValues(tsr.Values, nil)
	}
	vec := bld.NewUint16Array()
	return tensor.NewUint16(vec.Data(), tsr.Shape64(), tsr.Strides64(), tsr.DimNames())
}

// FromArrow intializes this tensor from an arrow tensor of same type
// cpy = true means make a copy of the arrow data, otherwise it directly
// refers to its values slice -- we do not Retain() on that data so it is up
// to the go GC and / or your own memory management policies to ensure the data
// remains intact!
func (tsr *Uint16) FromArrow(arw *tensor.Uint16, cpy bool) {
	nms := make([]string, arw.NumDims()) // note: would be nice if it exposed DimNames()
	for i := range nms {
		nms[i] = arw.DimName(i)
	}
	tsr.SetShape64(arw.Shape(), arw.Strides(), nms)
	if cpy {
		vls := arw.Uint16Values()
		tsr.Values = make([]uint16, tsr.Len())
		copy(tsr.Values, vls)
	} else {
		tsr.Values = arw.Uint16Values()
	}
	// note: doesn't look like the Data() exposes the nulls themselves so it is not
	// clear we can copy the null values -- nor does it seem that the tensor class
	// exposes it either!  https://github.com/apache/arrow/issues/3496
	// nln := arw.Data().NullN()
	// if nln > 0 {
	// }
}

// Dims is the gonum/mat.Matrix interface method for returning the dimensionality of the
// 2D Matrix.  Assumes Row-major ordering and logs an error if NumDims < 2.
func (tsr *Uint16) Dims() (r, c int) {
	nd := tsr.NumDims()
	if nd < 2 {
		log.Println("etensor Dims gonum Matrix call made on Tensor with dims < 2")
		return 0, 0
	}
	return tsr.Dim(nd - 2), tsr.Dim(nd - 1)
}

// At is the gonum/mat.Matrix interface method for returning 2D matrix element at given
// row, column index.  Assumes Row-major ordering and logs an error if NumDims < 2.
func (tsr *Uint16) At(i, j int) float64 {
	nd := tsr.NumDims()
	if nd < 2 {
		log.Println("etensor Dims gonum Matrix call made on Tensor with dims < 2")
		return 0
	} else if nd == 2 {
		return tsr.FloatValue([]int{i, j})
	} else {
		ix := make([]int, nd)
		ix[nd-2] = i
		ix[nd-1] = j
		return tsr.FloatValue(ix)
	}
}

// T is the gonum/mat.Matrix transpose method.
// It performs an implicit transpose by returning the receiver inside a Transpose.
func (tsr *Uint16) T() mat.Matrix {
	return mat.Transpose{tsr}
}

// Symmetric is the gonum/mat.Matrix interface method for returning the dimensionality of a symmetric
// 2D Matrix.  Logs error if called on non-symmetric matrix.
func (tsr *Uint16) Symmetric() (r int) {
	nd := tsr.NumDims()
	if nd < 2 {
		log.Println("etensor Symmetric gonum Matrix call made on Tensor with dims < 2")
		return 0
	}
	if tsr.Dim(nd-2) != tsr.Dim(nd-1) {
		log.Println("etensor Symmatrics gonum Matrix call made on Tensor that is not symmetric")
		return 0
	}
	return tsr.Dim(nd - 1)
}

// SymmetricDim is the gonum/mat.Matrix interface method for returning the dimensionality of a symmetric
// 2D Matrix.  Logs error if called on non-symmetric matrix.
func (tsr *Uint16) SymmetricDim() int {
	nd := tsr.NumDims()
	if nd < 2 {
		log.Println("etensor Symmetric gonum Matrix call made on Tensor with dims < 2")
		return 0
	}
	if tsr.Dim(nd-2) != tsr.Dim(nd-1) {
		log.Println("etensor Symmetric gonum Matrix call made on Tensor that is not symmetric")
		return 0
	}
	return tsr.Dim(nd - 1)
}

// SetMetaData sets a key=value meta data (stored as a map[string]string).
// For TensorGrid display: top-zero=+/-, odd-row=+/-, image=+/-,
// min, max set fixed min / max values, background=color
func (tsr *Uint16) SetMetaData(key, val string) {
	if tsr.Meta == nil {
		tsr.Meta = make(map[string]string)
	}
	tsr.Meta[key] = val
}

// MetaData retrieves value of given key, bool = false if not set
func (tsr *Uint16) MetaData(key string) (string, bool) {
	if tsr.Meta == nil {
		return "", false
	}
	val, ok := tsr.Meta[key]
	return val, ok
}

// MetaDataMap returns the underlying map used for meta data
func (tsr *Uint16) MetaDataMap() map[string]string {
	return tsr.Meta
}

// CopyMetaData copies meta data from given source tensor
func (tsr *Uint16) CopyMetaData(frm Tensor) {
	fmap := frm.MetaDataMap()
	if len(fmap) == 0 {
		return
	}
	if tsr.Meta == nil {
		tsr.Meta = make(map[string]string)
	}
	for k, v := range fmap {
		tsr.Meta[k] = v
	}
}

// Int8 is an n-dim array of int8s.
type Int8 struct {
	Shape
	Values []int8
	Nulls  bitslice.Slice
	Meta   map[string]string
}

// NewInt8 returns a new n-dimensional array of int8s.
// If strides is nil, row-major strides will be inferred.
// If names is nil, a slice of empty strings will be created.
// Nulls are initialized to nil.
func NewInt8(shape, strides []int, names []string) *Int8 {
	tsr := &Int8{}
	tsr.SetShape(shape, strides, names)
	tsr.Values = make([]int8, tsr.Len())
	return tsr
}

// NewInt8Shape returns a new n-dimensional array of int8s.
// Using shape structure instead of separate slices, and optionally
// existing values if vals != nil (must be of proper length) -- we
// directly set our internal Values = vals, thereby sharing the same
// underlying data. Nulls are initialized to nil.
func NewInt8Shape(shape *Shape, vals []int8) *Int8 {
	tsr := &Int8{}
	tsr.CopyShape(shape)
	if vals != nil {
		if len(vals) != tsr.Len() {
			log.Printf("etensor.NewInt8Shape: length of provided vals: %d not proper length: %d", len(vals), tsr.Len())
			tsr.Values = make([]int8, tsr.Len())
		} else {
			tsr.Values = vals
		}
	} else {
		tsr.Values = make([]int8, tsr.Len())
	}
	return tsr
}

func (tsr *Int8) ShapeObj() *Shape      { return &tsr.Shape }
func (tsr *Int8) DataType() Type        { return INT8 }
func (tsr *Int8) Value(i []int) int8    { j := tsr.Offset(i); return tsr.Values[j] }
func (tsr *Int8) Value1D(i int) int8    { return tsr.Values[i] }
func (tsr *Int8) Set(i []int, val int8) { j := tsr.Offset(i); tsr.Values[j] = val }
func (tsr *Int8) Set1D(i int, val int8) { tsr.Values[i] = val }
func (tsr *Int8) AddScalar(i []int, val int8) int8 {
	j := tsr.Offset(i)
	tsr.Values[j] += val
	return tsr.Values[j]
}
func (tsr *Int8) MulScalar(i []int, val int8) int8 {
	j := tsr.Offset(i)
	tsr.Values[j] *= val
	return tsr.Values[j]
}

// IsNull returns true if the given index has been flagged as a Null
// (undefined, not present) value
func (tsr *Int8) IsNull(i []int) bool {
	if tsr.Nulls == nil {
		return false
	}
	j := tsr.Offset(i)
	return tsr.Nulls.Index(j)
}

// IsNull1D returns true if the given 1-dimensional index has been flagged as a Null
// (undefined, not present) value
func (tsr *Int8) IsNull1D(i int) bool {
	if tsr.Nulls == nil {
		return false
	}
	return tsr.Nulls.Index(i)
}

// SetNull sets whether given index has a null value or not.
// All values are assumed valid (non-Null) until marked otherwise, and calling
// this method creates a Null bitslice map if one has not already been set yet.
func (tsr *Int8) SetNull(i []int, nul bool) {
	if tsr.Nulls == nil {
		tsr.Nulls = bitslice.Make(tsr.Len(), 0)
	}
	j := tsr.Offset(i)
	tsr.Nulls.Set(j, nul)
}

// SetNull1D sets whether given 1-dimensional index has a null value or not.
// All values are assumed valid (non-Null) until marked otherwise, and calling
// this method creates a Null bitslice map if one has not already been set yet.
func (tsr *Int8) SetNull1D(i int, nul bool) {
	if tsr.Nulls == nil {
		tsr.Nulls = bitslice.Make(tsr.Len(), 0)
	}
	tsr.Nulls.Set(i, nul)
}

func (tsr *Int8) FloatValue(i []int) float64      { j := tsr.Offset(i); return float64(tsr.Values[j]) }
func (tsr *Int8) SetFloat(i []int, val float64) { j := tsr.Offset(i); tsr.Values[j] = int8(val) }

func (tsr *Int8) StringValue(i []int) string { j := tsr.Offset(i); return laser.ToString(tsr.Values[j]) }
func (tsr *Int8) SetString(i []int, val string) {
	if fv, err := strconv.ParseFloat(val, 64); err == nil {
		j := tsr.Offset(i)
		tsr.Values[j] = int8(fv)
	}
}

func (tsr *Int8) FloatValue1D(off int) float64      { return float64(tsr.Values[off]) }
func (tsr *Int8) SetFloat1D(off int, val float64) { tsr.Values[off] = int8(val) }

func (tsr *Int8) FloatValueRowCell(row, cell int) float64 {
	_, sz := tsr.RowCellSize()
	return float64(tsr.Values[row*sz+cell])
}
func (tsr *Int8) SetFloatRowCell(row, cell int, val float64) {
	_, sz := tsr.RowCellSize()
	tsr.Values[row*sz+cell] = int8(val)
}

// Floats sets []float64 slice of all elements in the tensor
// (length is ensured to be sufficient).
// This can be used for all of the gonum/floats methods
// for basic math, gonum/stats, etc.
func (tsr *Int8) Floats(flt *[]float64) {
	SetFloat64SliceLen(flt, len(tsr.Values))
	for j, vl := range tsr.Values {
		(*flt)[j] = float64(vl)
	}
}

// SetFloats sets tensor values from a []float64 slice (copies values).
func (tsr *Int8) SetFloats(vals []float64) {
	sz := min(len(tsr.Values), len(vals))
	for j := 0; j < sz; j++ {
		tsr.Values[j] = int8(vals[j])
	}
}

func (tsr *Int8) StringValue1D(off int) string { return laser.ToString(tsr.Values[off]) }
func (tsr *Int8) SetString1D(off int, val string) {
	if fv, err := strconv.ParseFloat(val, 64); err == nil {
		tsr.Values[off] = int8(fv)
	}
}

func (tsr *Int8) StringValueRowCell(row, cell int) string {
	_, sz := tsr.RowCellSize()
	return laser.ToString(tsr.Values[row*sz+cell])
}
func (tsr *Int8) SetStringRowCell(row, cell int, val string) {
	if fv, err := strconv.ParseFloat(val, 64); err == nil {
		_, sz := tsr.RowCellSize()
		tsr.Values[row*sz+cell] = int8(fv)
	}
}

// Range returns the min, max (and associated indexes, -1 = no values) for the tensor.
// This is needed for display and is thus in the core api in optimized form
// Other math operations can be done using gonum/floats package.
func (tsr *Int8) Range() (min, max float64, minIndex, maxIndex int) {
	minIndex = -1
	maxIndex = -1
	for j, vl := range tsr.Values {
		fv := float64(vl)
		if math.IsNaN(fv) {
			continue
		}
		if fv < min || minIndex < 0 {
			min = fv
			minIndex = j
		}
		if fv > max || maxIndex < 0 {
			max = fv
			maxIndex = j
		}
	}
	return
}

// Agg applies given aggregation function to each element in the tensor
// (automatically skips IsNull and NaN elements), using float64 conversions of the values.
// init is the initial value for the agg variable. returns final aggregate value
func (tsr *Int8) Agg(ini float64, fun AggFunc) float64 {
	ag := ini
	for j, vl := range tsr.Values {
		val := float64(vl)
		if !tsr.IsNull1D(j) && !math.IsNaN(val) {
			ag = fun(j, val, ag)
		}
	}
	return ag
}

// Eval applies given function to each element in the tensor (automatically
// skips IsNull and NaN elements), using float64 conversions of the values.
// Puts the results into given float64 slice, which is ensured to be of the proper length.
func (tsr *Int8) Eval(res *[]float64, fun EvalFunc) {
	ln := tsr.Len()
	if len(*res) != ln {
		*res = make([]float64, ln)
	}
	for j, vl := range tsr.Values {
		val := float64(vl)
		if !tsr.IsNull1D(j) && !math.IsNaN(val) {
			(*res)[j] = fun(j, val)
		}
	}
}

// SetFunc applies given function to each element in the tensor (automatically
// skips IsNull and NaN elements), using float64 conversions of the values.
// Writes the results back into the same tensor elements.
func (tsr *Int8) SetFunc(fun EvalFunc) {
	for j, vl := range tsr.Values {
		val := float64(vl)
		if !tsr.IsNull1D(j) && !math.IsNaN(val) {
			tsr.Values[j] = int8(fun(j, val))
		}
	}
}

// SetZeros is simple convenience function initialize all values to 0
func (tsr *Int8) SetZeros() {
	for j := range tsr.Values {
		tsr.Values[j] = 0
	}
}

// Clone clones this tensor, creating a duplicate copy of itself with its
// own separate memory representation of all the values, and returns
// that as a Tensor (which can be converted into the known type as needed).
func (tsr *Int8) Clone() Tensor {
	csr := NewInt8Shape(&tsr.Shape, nil)
	copy(csr.Values, tsr.Values)
	if tsr.Nulls != nil {
		csr.Nulls = tsr.Nulls.Clone()
	}
	return csr
}

// CopyFrom copies all avail values from other tensor into this tensor, with an
// optimized implementation if the other tensor is of the same type, and
// otherwise it goes through appropriate standard type.
// Copies Null state as well if present.
func (tsr *Int8) CopyFrom(frm Tensor) {
	if fsm, ok := frm.(*Int8); ok {
		copy(tsr.Values, fsm.Values)
		if fsm.Nulls != nil {
			if tsr.Nulls == nil {
				tsr.Nulls = bitslice.Make(tsr.Len(), 0)
			}
			copy(tsr.Nulls, fsm.Nulls)
		}
		return
	}
	sz := min(len(tsr.Values), frm.Len())
	for i := 0; i < sz; i++ {
		tsr.Values[i] = int8(frm.FloatValue1D(i))
		if frm.IsNull1D(i) {
			tsr.SetNull1D(i, true)
		}
	}
}

// CopyShapeFrom copies just the shape from given source tensor
// calling SetShape with the shape params from source (see for more docs).
func (tsr *Int8) CopyShapeFrom(frm Tensor) {
	tsr.SetShape(frm.Shapes(), frm.Strides(), frm.DimNames())
}

// CopyCellsFrom copies given range of values from other tensor into this tensor,
// using flat 1D indexes: to = starting index in this Tensor to start copying into,
// start = starting index on from Tensor to start copying from, and n = number of
// values to copy.  Uses an optimized implementation if the other tensor is
// of the same type, and otherwise it goes through appropriate standard type.
func (tsr *Int8) CopyCellsFrom(frm Tensor, to, start, n int) {
	if fsm, ok := frm.(*Int8); ok {
		for i := 0; i < n; i++ {
			tsr.Values[to+i] = fsm.Values[start+i]
			if fsm.IsNull1D(start + i) {
				tsr.SetNull1D(to+i, true)
			}
		}
		return
	}
	for i := 0; i < n; i++ {
		tsr.Values[to+i] = int8(frm.FloatValue1D(start + i))
		if frm.IsNull1D(start + i) {
			tsr.SetNull1D(to+i, true)
		}
	}
}

// SetShape sets the shape params, resizing backing storage appropriately
func (tsr *Int8) SetShape(shape, strides []int, names []string) {
	tsr.Shape.SetShape(shape, strides, names)
	nln := tsr.Len()
	if cap(tsr.Values) >= nln {
		tsr.Values = tsr.Values[0:nln]
	} else {
		nv := make([]int8, nln)
		copy(nv, tsr.Values)
		tsr.Values = nv
	}
	if tsr.Nulls != nil {
		tsr.Nulls.SetLen(nln)
	}
}

// SetNumRows sets the number of rows (outer-most dimension) in a RowMajor organized tensor.
func (tsr *Int8) SetNumRows(rows int) {
	if !tsr.IsRowMajor() {
		return
	}
	rows = max(1, rows) // must be > 0
	_, cells := tsr.RowCellSize()
	nln := rows * cells
	tsr.Shape.Shp[0] = rows
	if cap(tsr.Values) >= nln {
		tsr.Values = tsr.Values[0:nln]
	} else {
		nv := make([]int8, nln)
		copy(nv, tsr.Values)
		tsr.Values = nv
	}
	if tsr.Nulls != nil {
		tsr.Nulls.SetLen(nln)
	}
}

// SubSpace returns a new tensor with innermost subspace at given
// offset(s) in outermost dimension(s) (len(offs) < NumDims).
// Only valid for row or column major layouts.
// The new tensor points to the values of the this tensor (i.e., modifications
// will affect both), as its Values slice is a view onto the original (which
// is why only inner-most contiguous supsaces are supported).
// Use Clone() method to separate the two.
// Null value bits are NOT shared but are copied if present.
func (tsr *Int8) SubSpace(offs []int) Tensor {
	ss, _ := tsr.SubSpaceTry(offs)
	return ss
}

// SubSpaceTry returns a new tensor with innermost subspace at given
// offset(s) in outermost dimension(s) (len(offs) < NumDims).
// Try version returns an error message if the offs do not fit in tensor Shape.
// Only valid for row or column major layouts.
// The new tensor points to the values of the this tensor (i.e., modifications
// will affect both), as its Values slice is a view onto the original (which
// is why only inner-most contiguous supsaces are supported).
// Use Clone() method to separate the two.
// Null value bits are NOT shared but are copied if present.
func (tsr *Int8) SubSpaceTry(offs []int) (Tensor, error) {
	nd := tsr.NumDims()
	od := len(offs)
	if od >= nd {
		return nil, errors.New("SubSpace len(offsets) for outer dimensions was >= NumDims -- must be less")
	}
	id := nd - od
	if tsr.IsRowMajor() {
		stsr := &Int8{}
		stsr.SetShape(tsr.Shp[od:], nil, tsr.Nms[od:]) // row major def
		sti := make([]int, nd)
		copy(sti, offs)
		stoff := tsr.Offset(sti)
		sln := stsr.Len()
		stsr.Values = tsr.Values[stoff : stoff+sln]
		if tsr.Nulls != nil {
			stsr.Nulls = tsr.Nulls.SubSlice(stoff, stoff+sln)
		}
		return stsr, nil
	} else if tsr.IsColMajor() {
		stsr := &Int8{}
		stsr.SetShape(tsr.Shp[:id], nil, tsr.Nms[:id])
		stsr.Strd = ColMajorStrides(stsr.Shp)
		sti := make([]int, nd)
		for i := id; i < nd; i++ {
			sti[i] = offs[i-id]
		}
		stoff := tsr.Offset(sti)
		sln := stsr.Len()
		stsr.Values = tsr.Values[stoff : stoff+sln]
		if tsr.Nulls != nil {
			stsr.Nulls = tsr.Nulls.SubSlice(stoff, stoff+sln)
		}
		return stsr, nil
	}
	return nil, errors.New("SubSpace only valid for RowMajor or ColMajor tensors")
}

// Label satisfies the gi.Labeler interface for a summary description of the tensor
func (tsr *Int8) Label() string {
	return fmt.Sprintf("Int8: %s", tsr.Shape.String())
}

// String satisfies the fmt.Stringer interface for string of tensor data
func (tsr *Int8) String() string {
	str := tsr.Label()
	sz := len(tsr.Values)
	if sz > 1000 {
		return str
	}
	var b strings.Builder
	b.WriteString(str)
	b.WriteString("\n")
	oddRow := true
	rows, cols, _, _ := Prjn2DShape(&tsr.Shape, oddRow)
	for r := 0; r < rows; r++ {
		rc, _ := Prjn2DCoords(&tsr.Shape, oddRow, r, 0)
		b.WriteString(fmt.Sprintf("%v: ", rc))
		for c := 0; c < cols; c++ {
			vl := Prjn2DValue(tsr, oddRow, r, c)
			b.WriteString(fmt.Sprintf("%7g ", vl))
		}
		b.WriteString("\n")
	}
	return b.String()
}

// ToArrow returns the apache arrow equivalent of the tensor
func (tsr *Int8) ToArrow() *tensor.Int8 {
	bld := array.NewInt8Builder(memory.DefaultAllocator)
	if tsr.Nulls != nil {
		bld.AppendValues(tsr.Values, tsr.Nulls.ToBools())
	} else {
		bld.AppendValues(tsr.Values, nil)
	}
	vec := bld.NewInt8Array()
	return tensor.NewInt8(vec.Data(), tsr.Shape64(), tsr.Strides64(), tsr.DimNames())
}

// FromArrow intializes this tensor from an arrow tensor of same type
// cpy = true means make a copy of the arrow data, otherwise it directly
// refers to its values slice -- we do not Retain() on that data so it is up
// to the go GC and / or your own memory management policies to ensure the data
// remains intact!
func (tsr *Int8) FromArrow(arw *tensor.Int8, cpy bool) {
	nms := make([]string, arw.NumDims()) // note: would be nice if it exposed DimNames()
	for i := range nms {
		nms[i] = arw.DimName(i)
	}
	tsr.SetShape64(arw.Shape(), arw.Strides(), nms)
	if cpy {
		vls := arw.Int8Values()
		tsr.Values = make([]int8, tsr.Len())
		copy(tsr.Values, vls)
	} else {
		tsr.Values = arw.Int8Values()
	}
	// note: doesn't look like the Data() exposes the nulls themselves so it is not
	// clear we can copy the null values -- nor does it seem that the tensor class
	// exposes it either!  https://github.com/apache/arrow/issues/3496
	// nln := arw.Data().NullN()
	// if nln > 0 {
	// }
}

// Dims is the gonum/mat.Matrix interface method for returning the dimensionality of the
// 2D Matrix.  Assumes Row-major ordering and logs an error if NumDims < 2.
func (tsr *Int8) Dims() (r, c int) {
	nd := tsr.NumDims()
	if nd < 2 {
		log.Println("etensor Dims gonum Matrix call made on Tensor with dims < 2")
		return 0, 0
	}
	return tsr.Dim(nd - 2), tsr.Dim(nd - 1)
}

// At is the gonum/mat.Matrix interface method for returning 2D matrix element at given
// row, column index.  Assumes Row-major ordering and logs an error if NumDims < 2.
func (tsr *Int8) At(i, j int) float64 {
	nd := tsr.NumDims()
	if nd < 2 {
		log.Println("etensor Dims gonum Matrix call made on Tensor with dims < 2")
		return 0
	} else if nd == 2 {
		return tsr.FloatValue([]int{i, j})
	} else {
		ix := make([]int, nd)
		ix[nd-2] = i
		ix[nd-1] = j
		return tsr.FloatValue(ix)
	}
}

// T is the gonum/mat.Matrix transpose method.
// It performs an implicit transpose by returning the receiver inside a Transpose.
func (tsr *Int8) T() mat.Matrix {
	return mat.Transpose{tsr}
}

// Symmetric is the gonum/mat.Matrix interface method for returning the dimensionality of a symmetric
// 2D Matrix.  Logs error if called on non-symmetric matrix.
func (tsr *Int8) Symmetric() (r int) {
	nd := tsr.NumDims()
	if nd < 2 {
		log.Println("etensor Symmetric gonum Matrix call made on Tensor with dims < 2")
		return 0
	}
	if tsr.Dim(nd-2) != tsr.Dim(nd-1) {
		log.Println("etensor Symmatrics gonum Matrix call made on Tensor that is not symmetric")
		return 0
	}
	return tsr.Dim(nd - 1)
}

// SymmetricDim is the gonum/mat.Matrix interface method for returning the dimensionality of a symmetric
// 2D Matrix.  Logs error if called on non-symmetric matrix.
func (tsr *Int8) SymmetricDim() int {
	nd := tsr.NumDims()
	if nd < 2 {
		log.Println("etensor Symmetric gonum Matrix call made on Tensor with dims < 2")
		return 0
	}
	if tsr.Dim(nd-2) != tsr.Dim(nd-1) {
		log.Println("etensor Symmetric gonum Matrix call made on Tensor that is not symmetric")
		return 0
	}
	return tsr.Dim(nd - 1)
}

// SetMetaData sets a key=value meta data (stored as a map[string]string).
// For TensorGrid display: top-zero=+/-, odd-row=+/-, image=+/-,
// min, max set fixed min / max values, background=color
func (tsr *Int8) SetMetaData(key, val string) {
	if tsr.Meta == nil {
		tsr.Meta = make(map[string]string)
	}
	tsr.Meta[key] = val
}

// MetaData retrieves value of given key, bool = false if not set
func (tsr *Int8) MetaData(key string) (string, bool) {
	if tsr.Meta == nil {
		return "", false
	}
	val, ok := tsr.Meta[key]
	return val, ok
}

// MetaDataMap returns the underlying map used for meta data
func (tsr *Int8) MetaDataMap() map[string]string {
	return tsr.Meta
}

// CopyMetaData copies meta data from given source tensor
func (tsr *Int8) CopyMetaData(frm Tensor) {
	fmap := frm.MetaDataMap()
	if len(fmap) == 0 {
		return
	}
	if tsr.Meta == nil {
		tsr.Meta = make(map[string]string)
	}
	for k, v := range fmap {
		tsr.Meta[k] = v
	}
}

// Uint8 is an n-dim array of uint8s.
type Uint8 struct {
	Shape
	Values []uint8
	Nulls  bitslice.Slice
	Meta   map[string]string
}

// NewUint8 returns a new n-dimensional array of uint8s.
// If strides is nil, row-major strides will be inferred.
// If names is nil, a slice of empty strings will be created.
// Nulls are initialized to nil.
func NewUint8(shape, strides []int, names []string) *Uint8 {
	tsr := &Uint8{}
	tsr.SetShape(shape, strides, names)
	tsr.Values = make([]uint8, tsr.Len())
	return tsr
}

// NewUint8Shape returns a new n-dimensional array of uint8s.
// Using shape structure instead of separate slices, and optionally
// existing values if vals != nil (must be of proper length) -- we
// directly set our internal Values = vals, thereby sharing the same
// underlying data. Nulls are initialized to nil.
func NewUint8Shape(shape *Shape, vals []uint8) *Uint8 {
	tsr := &Uint8{}
	tsr.CopyShape(shape)
	if vals != nil {
		if len(vals) != tsr.Len() {
			log.Printf("etensor.NewUint8Shape: length of provided vals: %d not proper length: %d", len(vals), tsr.Len())
			tsr.Values = make([]uint8, tsr.Len())
		} else {
			tsr.Values = vals
		}
	} else {
		tsr.Values = make([]uint8, tsr.Len())
	}
	return tsr
}

func (tsr *Uint8) ShapeObj() *Shape       { return &tsr.Shape }
func (tsr *Uint8) DataType() Type         { return UINT8 }
func (tsr *Uint8) Value(i []int) uint8    { j := tsr.Offset(i); return tsr.Values[j] }
func (tsr *Uint8) Value1D(i int) uint8    { return tsr.Values[i] }
func (tsr *Uint8) Set(i []int, val uint8) { j := tsr.Offset(i); tsr.Values[j] = val }
func (tsr *Uint8) Set1D(i int, val uint8) { tsr.Values[i] = val }
func (tsr *Uint8) AddScalar(i []int, val uint8) uint8 {
	j := tsr.Offset(i)
	tsr.Values[j] += val
	return tsr.Values[j]
}
func (tsr *Uint8) MulScalar(i []int, val uint8) uint8 {
	j := tsr.Offset(i)
	tsr.Values[j] *= val
	return tsr.Values[j]
}

// IsNull returns true if the given index has been flagged as a Null
// (undefined, not present) value
func (tsr *Uint8) IsNull(i []int) bool {
	if tsr.Nulls == nil {
		return false
	}
	j := tsr.Offset(i)
	return tsr.Nulls.Index(j)
}

// IsNull1D returns true if the given 1-dimensional index has been flagged as a Null
// (undefined, not present) value
func (tsr *Uint8) IsNull1D(i int) bool {
	if tsr.Nulls == nil {
		return false
	}
	return tsr.Nulls.Index(i)
}

// SetNull sets whether given index has a null value or not.
// All values are assumed valid (non-Null) until marked otherwise, and calling
// this method creates a Null bitslice map if one has not already been set yet.
func (tsr *Uint8) SetNull(i []int, nul bool) {
	if tsr.Nulls == nil {
		tsr.Nulls = bitslice.Make(tsr.Len(), 0)
	}
	j := tsr.Offset(i)
	tsr.Nulls.Set(j, nul)
}

// SetNull1D sets whether given 1-dimensional index has a null value or not.
// All values are assumed valid (non-Null) until marked otherwise, and calling
// this method creates a Null bitslice map if one has not already been set yet.
func (tsr *Uint8) SetNull1D(i int, nul bool) {
	if tsr.Nulls == nil {
		tsr.Nulls = bitslice.Make(tsr.Len(), 0)
	}
	tsr.Nulls.Set(i, nul)
}

func (tsr *Uint8) FloatValue(i []int) float64      { j := tsr.Offset(i); return float64(tsr.Values[j]) }
func (tsr *Uint8) SetFloat(i []int, val float64) { j := tsr.Offset(i); tsr.Values[j] = uint8(val) }

func (tsr *Uint8) StringValue(i []int) string { j := tsr.Offset(i); return laser.ToString(tsr.Values[j]) }
func (tsr *Uint8) SetString(i []int, val string) {
	if fv, err := strconv.ParseFloat(val, 64); err == nil {
		j := tsr.Offset(i)
		tsr.Values[j] = uint8(fv)
	}
}

func (tsr *Uint8) FloatValue1D(off int) float64      { return float64(tsr.Values[off]) }
func (tsr *Uint8) SetFloat1D(off int, val float64) { tsr.Values[off] = uint8(val) }

func (tsr *Uint8) FloatValueRowCell(row, cell int) float64 {
	_, sz := tsr.RowCellSize()
	return float64(tsr.Values[row*sz+cell])
}
func (tsr *Uint8) SetFloatRowCell(row, cell int, val float64) {
	_, sz := tsr.RowCellSize()
	tsr.Values[row*sz+cell] = uint8(val)
}

// Floats sets []float64 slice of all elements in the tensor
// (length is ensured to be sufficient).
// This can be used for all of the gonum/floats methods
// for basic math, gonum/stats, etc.
func (tsr *Uint8) Floats(flt *[]float64) {
	SetFloat64SliceLen(flt, len(tsr.Values))
	for j, vl := range tsr.Values {
		(*flt)[j] = float64(vl)
	}
}

// SetFloats sets tensor values from a []float64 slice (copies values).
func (tsr *Uint8) SetFloats(vals []float64) {
	sz := min(len(tsr.Values), len(vals))
	for j := 0; j < sz; j++ {
		tsr.Values[j] = uint8(vals[j])
	}
}

func (tsr *Uint8) StringValue1D(off int) string { return laser.ToString(tsr.Values[off]) }
func (tsr *Uint8) SetString1D(off int, val string) {
	if fv, err := strconv.ParseFloat(val, 64); err == nil {
		tsr.Values[off] = uint8(fv)
	}
}

func (tsr *Uint8) StringValueRowCell(row, cell int) string {
	_, sz := tsr.RowCellSize()
	return laser.ToString(tsr.Values[row*sz+cell])
}
func (tsr *Uint8) SetStringRowCell(row, cell int, val string) {
	if fv, err := strconv.ParseFloat(val, 64); err == nil {
		_, sz := tsr.RowCellSize()
		tsr.Values[row*sz+cell] = uint8(fv)
	}
}

// Range returns the min, max (and associated indexes, -1 = no values) for the tensor.
// This is needed for display and is thus in the core api in optimized form
// Other math operations can be done using gonum/floats package.
func (tsr *Uint8) Range() (min, max float64, minIndex, maxIndex int) {
	minIndex = -1
	maxIndex = -1
	for j, vl := range tsr.Values {
		fv := float64(vl)
		if math.IsNaN(fv) {
			continue
		}
		if fv < min || minIndex < 0 {
			min = fv
			minIndex = j
		}
		if fv > max || maxIndex < 0 {
			max = fv
			maxIndex = j
		}
	}
	return
}

// Agg applies given aggregation function to each element in the tensor
// (automatically skips IsNull and NaN elements), using float64 conversions of the values.
// init is the initial value for the agg variable. returns final aggregate value
func (tsr *Uint8) Agg(ini float64, fun AggFunc) float64 {
	ag := ini
	for j, vl := range tsr.Values {
		val := float64(vl)
		if !tsr.IsNull1D(j) && !math.IsNaN(val) {
			ag = fun(j, val, ag)
		}
	}
	return ag
}

// Eval applies given function to each element in the tensor (automatically
// skips IsNull and NaN elements), using float64 conversions of the values.
// Puts the results into given float64 slice, which is ensured to be of the proper length.
func (tsr *Uint8) Eval(res *[]float64, fun EvalFunc) {
	ln := tsr.Len()
	if len(*res) != ln {
		*res = make([]float64, ln)
	}
	for j, vl := range tsr.Values {
		val := float64(vl)
		if !tsr.IsNull1D(j) && !math.IsNaN(val) {
			(*res)[j] = fun(j, val)
		}
	}
}

// SetFunc applies given function to each element in the tensor (automatically
// skips IsNull and NaN elements), using float64 conversions of the values.
// Writes the results back into the same tensor elements.
func (tsr *Uint8) SetFunc(fun EvalFunc) {
	for j, vl := range tsr.Values {
		val := float64(vl)
		if !tsr.IsNull1D(j) && !math.IsNaN(val) {
			tsr.Values[j] = uint8(fun(j, val))
		}
	}
}

// SetZeros is simple convenience function initialize all values to 0
func (tsr *Uint8) SetZeros() {
	for j := range tsr.Values {
		tsr.Values[j] = 0
	}
}

// Clone clones this tensor, creating a duplicate copy of itself with its
// own separate memory representation of all the values, and returns
// that as a Tensor (which can be converted into the known type as needed).
func (tsr *Uint8) Clone() Tensor {
	csr := NewUint8Shape(&tsr.Shape, nil)
	copy(csr.Values, tsr.Values)
	if tsr.Nulls != nil {
		csr.Nulls = tsr.Nulls.Clone()
	}
	return csr
}

// CopyFrom copies all avail values from other tensor into this tensor, with an
// optimized implementation if the other tensor is of the same type, and
// otherwise it goes through appropriate standard type.
// Copies Null state as well if present.
func (tsr *Uint8) CopyFrom(frm Tensor) {
	if fsm, ok := frm.(*Uint8); ok {
		copy(tsr.Values, fsm.Values)
		if fsm.Nulls != nil {
			if tsr.Nulls == nil {
				tsr.Nulls = bitslice.Make(tsr.Len(), 0)
			}
			copy(tsr.Nulls, fsm.Nulls)
		}
		return
	}
	sz := min(len(tsr.Values), frm.Len())
	for i := 0; i < sz; i++ {
		tsr.Values[i] = uint8(frm.FloatValue1D(i))
		if frm.IsNull1D(i) {
			tsr.SetNull1D(i, true)
		}
	}
}

// CopyShapeFrom copies just the shape from given source tensor
// calling SetShape with the shape params from source (see for more docs).
func (tsr *Uint8) CopyShapeFrom(frm Tensor) {
	tsr.SetShape(frm.Shapes(), frm.Strides(), frm.DimNames())
}

// CopyCellsFrom copies given range of values from other tensor into this tensor,
// using flat 1D indexes: to = starting index in this Tensor to start copying into,
// start = starting index on from Tensor to start copying from, and n = number of
// values to copy.  Uses an optimized implementation if the other tensor is
// of the same type, and otherwise it goes through appropriate standard type.
func (tsr *Uint8) CopyCellsFrom(frm Tensor, to, start, n int) {
	if fsm, ok := frm.(*Uint8); ok {
		for i := 0; i < n; i++ {
			tsr.Values[to+i] = fsm.Values[start+i]
			if fsm.IsNull1D(start + i) {
				tsr.SetNull1D(to+i, true)
			}
		}
		return
	}
	for i := 0; i < n; i++ {
		tsr.Values[to+i] = uint8(frm.FloatValue1D(start + i))
		if frm.IsNull1D(start + i) {
			tsr.SetNull1D(to+i, true)
		}
	}
}

// SetShape sets the shape params, resizing backing storage appropriately
func (tsr *Uint8) SetShape(shape, strides []int, names []string) {
	tsr.Shape.SetShape(shape, strides, names)
	nln := tsr.Len()
	if cap(tsr.Values) >= nln {
		tsr.Values = tsr.Values[0:nln]
	} else {
		nv := make([]uint8, nln)
		copy(nv, tsr.Values)
		tsr.Values = nv
	}
	if tsr.Nulls != nil {
		tsr.Nulls.SetLen(nln)
	}
}

// SetNumRows sets the number of rows (outer-most dimension) in a RowMajor organized tensor.
func (tsr *Uint8) SetNumRows(rows int) {
	if !tsr.IsRowMajor() {
		return
	}
	rows = max(1, rows) // must be > 0
	_, cells := tsr.RowCellSize()
	nln := rows * cells
	tsr.Shape.Shp[0] = rows
	if cap(tsr.Values) >= nln {
		tsr.Values = tsr.Values[0:nln]
	} else {
		nv := make([]uint8, nln)
		copy(nv, tsr.Values)
		tsr.Values = nv
	}
	if tsr.Nulls != nil {
		tsr.Nulls.SetLen(nln)
	}
}

// SubSpace returns a new tensor with innermost subspace at given
// offset(s) in outermost dimension(s) (len(offs) < NumDims).
// Only valid for row or column major layouts.
// The new tensor points to the values of the this tensor (i.e., modifications
// will affect both), as its Values slice is a view onto the original (which
// is why only inner-most contiguous supsaces are supported).
// Use Clone() method to separate the two.
// Null value bits are NOT shared but are copied if present.
func (tsr *Uint8) SubSpace(offs []int) Tensor {
	ss, _ := tsr.SubSpaceTry(offs)
	return ss
}

// SubSpaceTry returns a new tensor with innermost subspace at given
// offset(s) in outermost dimension(s) (len(offs) < NumDims).
// Try version returns an error message if the offs do not fit in tensor Shape.
// Only valid for row or column major layouts.
// The new tensor points to the values of the this tensor (i.e., modifications
// will affect both), as its Values slice is a view onto the original (which
// is why only inner-most contiguous supsaces are supported).
// Use Clone() method to separate the two.
// Null value bits are NOT shared but are copied if present.
func (tsr *Uint8) SubSpaceTry(offs []int) (Tensor, error) {
	nd := tsr.NumDims()
	od := len(offs)
	if od >= nd {
		return nil, errors.New("SubSpace len(offsets) for outer dimensions was >= NumDims -- must be less")
	}
	id := nd - od
	if tsr.IsRowMajor() {
		stsr := &Uint8{}
		stsr.SetShape(tsr.Shp[od:], nil, tsr.Nms[od:]) // row major def
		sti := make([]int, nd)
		copy(sti, offs)
		stoff := tsr.Offset(sti)
		sln := stsr.Len()
		stsr.Values = tsr.Values[stoff : stoff+sln]
		if tsr.Nulls != nil {
			stsr.Nulls = tsr.Nulls.SubSlice(stoff, stoff+sln)
		}
		return stsr, nil
	} else if tsr.IsColMajor() {
		stsr := &Uint8{}
		stsr.SetShape(tsr.Shp[:id], nil, tsr.Nms[:id])
		stsr.Strd = ColMajorStrides(stsr.Shp)
		sti := make([]int, nd)
		for i := id; i < nd; i++ {
			sti[i] = offs[i-id]
		}
		stoff := tsr.Offset(sti)
		sln := stsr.Len()
		stsr.Values = tsr.Values[stoff : stoff+sln]
		if tsr.Nulls != nil {
			stsr.Nulls = tsr.Nulls.SubSlice(stoff, stoff+sln)
		}
		return stsr, nil
	}
	return nil, errors.New("SubSpace only valid for RowMajor or ColMajor tensors")
}

// Label satisfies the gi.Labeler interface for a summary description of the tensor
func (tsr *Uint8) Label() string {
	return fmt.Sprintf("Uint8: %s", tsr.Shape.String())
}

// String satisfies the fmt.Stringer interface for string of tensor data
func (tsr *Uint8) String() string {
	str := tsr.Label()
	sz := len(tsr.Values)
	if sz > 1000 {
		return str
	}
	var b strings.Builder
	b.WriteString(str)
	b.WriteString("\n")
	oddRow := true
	rows, cols, _, _ := Prjn2DShape(&tsr.Shape, oddRow)
	for r := 0; r < rows; r++ {
		rc, _ := Prjn2DCoords(&tsr.Shape, oddRow, r, 0)
		b.WriteString(fmt.Sprintf("%v: ", rc))
		for c := 0; c < cols; c++ {
			vl := Prjn2DValue(tsr, oddRow, r, c)
			b.WriteString(fmt.Sprintf("%7g ", vl))
		}
		b.WriteString("\n")
	}
	return b.String()
}

// ToArrow returns the apache arrow equivalent of the tensor
func (tsr *Uint8) ToArrow() *tensor.Uint8 {
	bld := array.NewUint8Builder(memory.DefaultAllocator)
	if tsr.Nulls != nil {
		bld.AppendValues(tsr.Values, tsr.Nulls.ToBools())
	} else {
		bld.AppendValues(tsr.Values, nil)
	}
	vec := bld.NewUint8Array()
	return tensor.NewUint8(vec.Data(), tsr.Shape64(), tsr.Strides64(), tsr.DimNames())
}

// FromArrow intializes this tensor from an arrow tensor of same type
// cpy = true means make a copy of the arrow data, otherwise it directly
// refers to its values slice -- we do not Retain() on that data so it is up
// to the go GC and / or your own memory management policies to ensure the data
// remains intact!
func (tsr *Uint8) FromArrow(arw *tensor.Uint8, cpy bool) {
	nms := make([]string, arw.NumDims()) // note: would be nice if it exposed DimNames()
	for i := range nms {
		nms[i] = arw.DimName(i)
	}
	tsr.SetShape64(arw.Shape(), arw.Strides(), nms)
	if cpy {
		vls := arw.Uint8Values()
		tsr.Values = make([]uint8, tsr.Len())
		copy(tsr.Values, vls)
	} else {
		tsr.Values = arw.Uint8Values()
	}
	// note: doesn't look like the Data() exposes the nulls themselves so it is not
	// clear we can copy the null values -- nor does it seem that the tensor class
	// exposes it either!  https://github.com/apache/arrow/issues/3496
	// nln := arw.Data().NullN()
	// if nln > 0 {
	// }
}

// Dims is the gonum/mat.Matrix interface method for returning the dimensionality of the
// 2D Matrix.  Assumes Row-major ordering and logs an error if NumDims < 2.
func (tsr *Uint8) Dims() (r, c int) {
	nd := tsr.NumDims()
	if nd < 2 {
		log.Println("etensor Dims gonum Matrix call made on Tensor with dims < 2")
		return 0, 0
	}
	return tsr.Dim(nd - 2), tsr.Dim(nd - 1)
}

// At is the gonum/mat.Matrix interface method for returning 2D matrix element at given
// row, column index.  Assumes Row-major ordering and logs an error if NumDims < 2.
func (tsr *Uint8) At(i, j int) float64 {
	nd := tsr.NumDims()
	if nd < 2 {
		log.Println("etensor Dims gonum Matrix call made on Tensor with dims < 2")
		return 0
	} else if nd == 2 {
		return tsr.FloatValue([]int{i, j})
	} else {
		ix := make([]int, nd)
		ix[nd-2] = i
		ix[nd-1] = j
		return tsr.FloatValue(ix)
	}
}

// T is the gonum/mat.Matrix transpose method.
// It performs an implicit transpose by returning the receiver inside a Transpose.
func (tsr *Uint8) T() mat.Matrix {
	return mat.Transpose{tsr}
}

// Symmetric is the gonum/mat.Matrix interface method for returning the dimensionality of a symmetric
// 2D Matrix.  Logs error if called on non-symmetric matrix.
func (tsr *Uint8) Symmetric() (r int) {
	nd := tsr.NumDims()
	if nd < 2 {
		log.Println("etensor Symmetric gonum Matrix call made on Tensor with dims < 2")
		return 0
	}
	if tsr.Dim(nd-2) != tsr.Dim(nd-1) {
		log.Println("etensor Symmatrics gonum Matrix call made on Tensor that is not symmetric")
		return 0
	}
	return tsr.Dim(nd - 1)
}

// SymmetricDim is the gonum/mat.Matrix interface method for returning the dimensionality of a symmetric
// 2D Matrix.  Logs error if called on non-symmetric matrix.
func (tsr *Uint8) SymmetricDim() int {
	nd := tsr.NumDims()
	if nd < 2 {
		log.Println("etensor Symmetric gonum Matrix call made on Tensor with dims < 2")
		return 0
	}
	if tsr.Dim(nd-2) != tsr.Dim(nd-1) {
		log.Println("etensor Symmetric gonum Matrix call made on Tensor that is not symmetric")
		return 0
	}
	return tsr.Dim(nd - 1)
}

// SetMetaData sets a key=value meta data (stored as a map[string]string).
// For TensorGrid display: top-zero=+/-, odd-row=+/-, image=+/-,
// min, max set fixed min / max values, background=color
func (tsr *Uint8) SetMetaData(key, val string) {
	if tsr.Meta == nil {
		tsr.Meta = make(map[string]string)
	}
	tsr.Meta[key] = val
}

// MetaData retrieves value of given key, bool = false if not set
func (tsr *Uint8) MetaData(key string) (string, bool) {
	if tsr.Meta == nil {
		return "", false
	}
	val, ok := tsr.Meta[key]
	return val, ok
}

// MetaDataMap returns the underlying map used for meta data
func (tsr *Uint8) MetaDataMap() map[string]string {
	return tsr.Meta
}

// CopyMetaData copies meta data from given source tensor
func (tsr *Uint8) CopyMetaData(frm Tensor) {
	fmap := frm.MetaDataMap()
	if len(fmap) == 0 {
		return
	}
	if tsr.Meta == nil {
		tsr.Meta = make(map[string]string)
	}
	for k, v := range fmap {
		tsr.Meta[k] = v
	}
}

// New returns a new Tensor of given type, using our Type specifier which is
// isomorphic with arrow.Type
func New(dtype Type, shape, strides []int, names []string) Tensor {
	switch dtype {
	case BOOL:
		return NewBits(shape, strides, names)
	case INT64:
		return NewInt64(shape, strides, names)
	case UINT64:
		return NewUint64(shape, strides, names)
	case INT32:
		return NewInt32(shape, strides, names)
	case UINT32:
		return NewUint32(shape, strides, names)
	case FLOAT32:
		return NewFloat32(shape, strides, names)
	case INT16:
		return NewInt16(shape, strides, names)
	case UINT16:
		return NewUint16(shape, strides, names)
	case INT8:
		return NewInt8(shape, strides, names)
	case UINT8:
		return NewUint8(shape, strides, names)
	case FLOAT64:
		return NewFloat64(shape, strides, names)
	case STRING:
		return NewString(shape, strides, names)
	case INT:
		return NewInt(shape, strides, names)
	}
	return nil
}
